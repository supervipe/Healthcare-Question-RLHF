{"id": "26485091", "question": "Does the use of atypical antipsychotics as adjunctive therapy in depression result in cost savings?", "context": "Several atypical antipsychotics (AAPs) are used as second-line agents for treatment resistant depression. AAPs can be expensive compared to other treatment options and can cause several side effects.\n\nTo estimate healthcare costs and utilization of AAPs compared to other second-line agents.\n\nObservational study using Medicaid claims data (2006-2011). Subjects were depression-diagnosed adult members with at least two prescriptions of antidepressant medications followed by a second-line agent. Gamma generalized linear models (GLM) produced estimates of the difference in mean expenditures among treatment groups after adjusting for individual baseline characteristics using propensity scores. Negative binomial models produced estimates of the difference in number of hospitalizations and emergency department (ED) visits.\n\nA total of 3910 members received second-line treatment. Treatment groups were AAPs (n = 2211), augmentation agents other than AAPs (n = 1008), and antidepressant switching (n = 691). AAPs resulted in higher mean adjusted pharmacy costs and higher mean adjusted total mental health-related costs. Mean adjusted total healthcare costs and number of inpatient and ED visits were not different among treatments.", "target": "no", "year": "2016", "labels": ["BACKGROUND", "OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "11334578", "question": "Is there awareness of pharmaceutical expenditure in the reformed primary care system?", "context": "To evaluate the effectiveness of feeding information on pharmacy back to primary care doctors in order to create awareness (knowledge) of pharmaceutical expenditure (PE).\n\nRetrospective cross-sectional study, through personal interview.\n\nReformed PC, Sabadell, Barcelona.\n\nThe 80 PC doctors working with primary care teams.\n\nAs the personal feed-back on PE, each doctor was asked for the PE generated during 1997 and the mean cost of prescriptions to active and pensioner patients. The statistical test used was the t test to compare means for paired data, with p<0.05 the required level of significance.\n\nOut of the total doctors interviewed (80), 71 replies were obtained for the annual PE and 76 for the mean cost of prescriptions, for both active and pensioner patients. Significant differences were found between the annual PE in reality and doctors' estimates: around twelve million pesetas. The differences between the real mean costs of prescription and the estimates were also significant.", "target": "no", "year": "2001", "labels": ["OBJECTIVE", "DESIGN", "SETTING", "PARTICIPANTS", "INTERVENTIONS", "RESULTS"]}
{"id": "25699562", "question": "Does the Transmissible Liability Index (TLI) assessed in late childhood predict suicidal symptoms at young adulthood?", "context": "Our previous work demonstrated that the Transmissible Liability Index (TLI), an instrument designed as an index of liability for substance use disorder (SUD), is associated with risk of substance use disorder. This longitudinal study assessed whether TLI measured in 10-12-year-olds (late childhood) predicts suicidal behavior from age 12-14 (preadolescence) to age 25 (young adulthood). We hypothesized that TLI would predict number and severity of suicide attempts.\n\nSubjects were sons of men who had lifetime history of SUD (n = 250), called the High Average Risk (HAR) group, and sons of men with no lifetime history of a SUD (n = 250), called the Low Average Risk (LAR) group. The TLI was delineated at baseline (age 10-12), and age-specific versions were administered at 12-14, 16, 19, 22, and 25 years of age.\n\nTLI was significantly associated with number and severity of lifetime suicide attempts.", "target": "yes", "year": "2015", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "12094116", "question": "Is muscle power related to running speed with changes of direction?", "context": "The purpose of this study was to identify the relationships between leg muscle power and sprinting speed with changes of direction.\n\nthe study was designed to describe relationships between physical qualities and a component of sports performance.\n\ntesting was conducted in an indoor sports hall and a biomechanics laboratory.\n\n15 male participants were required to be free of injury and have recent experience competing in sports involving sprints with changes of direction.\n\nsubjects were timed in 8 m sprints in a straight line and with various changes of direction. They were also tested for bilateral and unilateral leg extensor muscle concentric power output by an isokinetic squat and reactive strength by a drop jump.\n\nThe correlations between concentric power and straight sprinting speed were non-significant whereas the relationships between reactive strength and straight speed were statistically significant. Correlations between muscle power and speed while changing direction were generally low and non-significant for concentric leg power with some moderate and significant (p<0.05) coefficients found for reactive strength. The participants who turned faster to one side tended to have a reactive strength dominance in the leg responsible for the push-off action.", "target": "yes", "year": "2002", "labels": ["BACKGROUND", "EXPERIMENTAL DESIGN", "SETTING", "PARTICIPANTS", "MEASURES", "RESULTS"]}
{"id": "19155657", "question": "Does accompanying metabolic syndrome contribute to heart dimensions in hypertensive patients?", "context": "Metabolic syndrome (MetS) is associated with increased risk for cardiovascular events. We evaluated heart dimensions in hypertensive patients with MetS.\n\nThe study included 75 hypertensive patients (34 males, 41 females; mean age 51+/-9 years) without coronary artery disease. Patients were evaluated in two groups depending on the presence or absence of MetS. Age- and gender-matched 20 healthy subjects (9 males, 11 females; mean age 50+/-5 years) comprised the control group. The diagnosis of MetS was based on the presence of at least three of five MetS criteria. Hypertension was defined as arterial blood pressure exceeding 140/85 mmHg on three consecutive measurements or the use of antihypertensive drugs. Echocardiographic measurements included interventricular septal thickness, left ventricular internal diameter, posterior wall thickness, aortic diameter, left atrial diameter, relative wall thickness, and left ventricular mass.\n\nMetabolic syndrome was present in 32 hypertensive patients (42.7%; 18 males, 14 females). The mean number of MetS criteria was 2.6+/-1.0 in the hypertensive group. Compared to the control group, patients with or without MetS exhibited significantly increased interventricular septum and posterior wall thickness, left atrial diameter, relative wall thickness, and left ventricular mass (p<0.05). The only significant difference between the two patient groups was that MetS was associated with a greater left atrial diameter (p=0.019). Left atrial diameter was correlated with the number of MetS criteria (r=0.51; p<0.001).", "target": "maybe", "year": "2008", "labels": ["OBJECTIVES", "STUDY DESIGN", "RESULTS"]}
{"id": "22990761", "question": "Cardiovascular risk in a rural adult West African population: is resting heart rate also relevant?", "context": "Elevated resting heart rate (RHR) is a neglected marker in cardiovascular risk factor studies of sub-Saharan African populations. This study aimed to determine the prevalence of elevated RHR and other risk factors for cardiovascular disease (CVD) and to investigate any associations between RHR and these risk factors in a rural population in Ghana.\n\nCross-sectional analysis.\n\nA total of 574 adults aged between 18-65 years were randomly sampled from a population register. Data collected included those on sociodemographic variables and anthropometric, blood pressure (BP), and RHR measurements. Within-person variability in RHR was calculated using data from repeat measurements taken 2 weeks apart.\n\nOf study participants, 36% were male. Prevalence of casual high BP was 19%. In the population, 10% were current cigarette smokers and habitual alcohol use was high at 56%. As measured by body mass index, 2% were obese and 14% had abdominal obesity. RHR was elevated (>90 bpm) in 19%. Overall, 79% of study participants were found to have at least one CVD risk factor. RHR was significantly associated with age, waist circumference, and BP. Individuals with an elevated RHR had a higher risk (OR 1.94, 95% CI 1.15-3.26%, p = 0.013) of casual high BP compared with participants with normal RHR independently of several established CVD risk factors. The regression dilution ratio of RHR was 0.75 (95% CI 0.62-0.89).", "target": "yes", "year": "2014", "labels": ["INTRODUCTION", "DESIGN", "METHODS", "RESULTS"]}
{"id": "10375486", "question": "Are variations in the use of carotid endarterectomy explained by population Need?", "context": "to describe variation in utilisation of carotid endarterectomy (CEA) within two English health regions and explore relationships between use, need and proximity to services.\n\nconsecutive case series of operations. Comparison at a population level with district stroke mortality, hospital admissions and material deprivation.\n\nstandardised utilisation rates for CEA and measures of inter-district variability. Spearman's rank correlation coefficients for associations between variables.\n\nvariation in utilisation rates was considerable (14-fold difference across district populations). More individuals had bilateral surgery in the Yorkshire region than in the Northern (11.7% vs. 5.5%, p=0.002). There was no association between utilisation rates for CEA and district stroke mortality (r=-0.06, 95% CI -0.41 to 0.30) or admission rates for stroke (r=0.17, 95% CI -0.2 to 0.49). There was a strong relationship between residence in districts where services were located and higher utilisation. Rates of CEA were lowest in the regions' most affluent wards.", "target": "no", "year": "1999", "labels": ["OBJECTIVES", "DESIGN", "MAIN OUTCOME MEASURES", "RESULTS"]}
{"id": "21756515", "question": "Does solid culture for tuberculosis influence clinical decision making in India?", "context": "Medical units at an academic tertiary referral hospital in Southern India.\n\nTo investigate the impact of solid culture on Löwenstein-Jensen medium on clinical decision making.\n\nIn a retrospective review of 150 culture-positive and 150 culture-negative consecutively sampled tuberculosis (TB) suspects, treatment decisions were analysed at presentation, after the availability of culture detection results and after the availability of drug susceptibility testing (DST) culture results.\n\nA total of 124 (82.7%) culture-positive patients and 35 (23.3%) culture-negative patients started anti-tuberculosis treatment prior to receiving their culture results; 101 patients (33.7%) returned for their results; two (1.3%) initiated treatment based on positive culture and no culture-negative patients discontinued treatment. DST was performed on 119 (79.3%) positive cultures: 30 (25.2%) showed any resistance, eight (6.7%) showed multidrug resistance and one (0.84%) showed extensively drug-resistant TB. Twenty-eight patients (23.5%) returned for their DST results. Based on DST, treatment was modified in four patients (3.4%).", "target": "maybe", "year": "2011", "labels": ["SETTING", "OBJECTIVE", "DESIGN", "RESULTS"]}
{"id": "19593710", "question": "Could ESC (Electronic Stability Control) change the way we drive?", "context": "ESC (Electronic Stability Control) is a crash avoidance technology that reduces the likelihood of collisions involving loss of control. Although past and emerging research indicates that ESC is effective in reducing collision rates and saving lives, and its inclusion in all vehicle platforms is encouraged, drivers may demonstrate behavioral adaptation or an overreliance on ESC that could offset or reduce its overall effectiveness. The main objective of the present study was to determine whether behavioral adaptation to ESC is likely to occur upon the widespread introduction of ESC into the Canadian vehicle fleet. Secondary objectives were to confirm the results of a previous ESC public survey and to generate a baseline measure for the future assessment of planned and ongoing ESC promotional activities in Canada.\n\nTwo separate telephone surveys evaluated drivers' perceptions and awareness of ESC. The first surveyed 500 randomly selected owners/drivers of passenger vehicles. The second surveyed 1017 owners/drivers of 2006-2008 ESC-equipped passenger vehicles from the provinces of Quebec and British Columbia, Canada.\n\nThough ESC drivers were much more likely than drivers of other vehicles to be aware of ESC (77% vs. 39%) and that their own vehicle was equipped with it (63% vs. 8%), 23 percent had never heard of it. Ninety percent of drivers who knew that their vehicle was equipped with ESC believed that ESC had made it safer to drive and reported being confident that ESC would work in an emergency. Twenty-three percent of ESC owners who knew their vehicle had ESC reported noticing long-lasting changes in their driving behavior since they began driving the vehicle.", "target": "yes", "year": "2009", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "26578404", "question": "Patient-Controlled Therapy of Breathlessness in Palliative Care: A New Therapeutic Concept for Opioid Administration?", "context": "Breathlessness is one of the most distressing symptoms experienced by patients with advanced cancer and noncancer diagnoses alike. Often, severity of breathlessness increases quickly, calling for rapid symptom control. Oral, buccal, and parenteral routes of provider-controlled drug administration have been described. It is unclear whether patient-controlled therapy (PCT) systems would be an additional treatment option.\n\nTo investigate whether intravenous opioid PCT can be an effective therapeutic method to reduce breathlessness in patients with advanced disease. Secondary aims were to study the feasibility and acceptance of opioid PCT in patients with refractory breathlessness.\n\nThis was a pilot observational study with 18 inpatients with advanced disease and refractory breathlessness receiving opioid PCT. Breathlessness was measured on a self-reported numeric rating scale. Richmond Agitation Sedation Scale scores, Palliative Performance Scale scores, vital signs, and a self-developed patient satisfaction questionnaire were used for measuring secondary outcomes. Descriptive and interference analyses (Friedman test) and post hoc analyses (Wilcoxon tests and Bonferroni corrections) were performed.\n\nEighteen of 815 patients (advanced cancer; median age = 57.5 years [range 36-81]; 77.8% female) received breathlessness symptom control with opioid PCT; daily morphine equivalent dose at Day 1 was median = 20.3 mg (5.0-49.6 mg); Day 2: 13.0 mg (1.0-78.5 mg); Day 3: 16.0 mg (8.3-47.0 mg). Numeric rating scale of current breathlessness decreased (baseline: median = 5 [range 1-10]; Day 1: median = 4 [range 0-8], P < 0.01; Day 2: median = 4 [range 0-5], P < 0.01). Physiological parameters were stable over time. On Day 3, 12/12 patients confirmed that this mode of application provided relief of breathlessness.", "target": "yes", "year": "2016", "labels": ["CONTEXT", "OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "22656647", "question": "Are acceptance rates of a national preventive home visit programme for older people socially imbalanced?", "context": "Preventive home visits are offered to community dwelling older people in Denmark aimed at maintaining their functional ability for as long as possible, but only two thirds of older people accept the offer from the municipalities. The purpose of this study is to investigate 1) whether socioeconomic status was associated with acceptance of preventive home visits among older people and 2) whether municipality invitational procedures for the preventive home visits modified the association.\n\nThe study population included 1,023 community dwelling 80-year-old individuals from the Danish intervention study on preventive home visits. Information on preventive home visit acceptance rates was obtained from questionnaires. Socioeconomic status was measured by financial assets obtained from national registry data, and invitational procedures were identified through the municipalities. Logistic regression analyses were used, adjusted by gender.\n\nOlder persons with high financial assets accepted preventive home visits more frequently than persons with low assets (adjusted OR = 1.5 (CI95%: 1.1-2.0)). However, the association was attenuated when adjusted by the invitational procedures. The odds ratio for accepting preventive home visits was larger among persons with low financial assets invited by a letter with a proposed date than among persons with high financial assets invited by other procedures, though these estimates had wide confidence intervals.", "target": "yes", "year": "2012", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "20828836", "question": "Is discordance in TEOAE and AABR outcomes predictable in newborns?", "context": "To determine the perinatal predictors of discordant screening outcomes based on a two-stage screening protocol with transient-evoked otoacoustic emissions (TEOAE) and automated auditory brainstem response (AABR).\n\nA cross-sectional study of infants tested with TEOAE and AABR under a hospital-based universal newborn hearing screening program in Lagos, Nigeria. Maternal and infant factors associated with discordant TEOAE and AABR outcomes were determined with multivariable logistic regression analyses adjusting for potential confounding factors.\n\nOf the 4718 infants enrolled under the program 1745 (36.9%) completed both TEOAE and AABR. Of this group, 1060 (60.7%) passed both TEOAE and AABR (\"true-negatives\"); 92 (5.3%) failed both TEOAE and AABR (\"true-positive\"); 571 (32.7%) failed TEOAE but passed AABR (\"false-positives\") while 22 (1.3%) passed TEOAE but failed AABR (\"false-negatives\"). Infants with false-positives were likely to be admitted into well-baby nursery (p=0.001), belong to mothers who attended antenatal care (p=0.010) or who delivered vaginally (p<0.001) compared to infants with true-negatives while infants with true-positives were also more likely to be delivered vaginally (p=0.002) or admitted into well-baby nursery (p=0.035) compared to infants with false-negatives. Infants with true-positives were significantly more likely to be delivered vaginally (p<0.001) and have severe hyperbilirubinemia (p=0.045) compared with infants with true-negatives. No association was observed between false-negatives and true-negatives. Antenatal care status, mode of delivery and nursery type were useful predictors of discordant outcomes among all infants undergoing screening (c-statistic=0.73).", "target": "yes", "year": "2010", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "20608141", "question": "PSA repeatedly fluctuating levels are reassuring enough to avoid biopsy?", "context": "Prostate-specific antigen (PSA) levels can show wide fluctuations when repeatedly measured. Here we investigatewd if: (a) biopsy timing influences the prostate cancer (PC) detection rate in patients with fluctuating PSA (flu-PSA) in comparison with patients with steadily increasing PSA (si-PSA); (b) PSA slope estimated in patients with flu-PSA predicts a different risk of cancer detection; (c) flu-PSA and si-PSA patients develop PC in topographically different sites; (d) the behaviour of pre-operative PSA is an expression of a disease with defferent characteristics to the following radical prostatectomy.\n\nThe study involved 211 patients who underwent at least a second biopsy after a first negative prostate biopsy. PSA Slope, PSA velocity (PSAV) and PSA doubling time (PSADT) were estimated. Flu-PSA level was defined as a PSA series with at least one PSA value lower than the one immediately preceding it.\n\n82 patients had flu-PSA levels and 129 si-PSA levels. There were no significant differences between the two groups in terms of cancer detection, clinical or pathological stage, but the si-PSA group with cancer had a higher Gleason score. No difference was found for PSA Slope between flu-PSA patients with cancer and those without.", "target": "no", "year": "2009", "labels": ["INTRODUCTION", "METHODS", "RESULTS"]}
{"id": "16046584", "question": "Menopausal hormone therapy and irregular endometrial bleeding: a potential role for uterine natural killer cells?", "context": "Irregular bleeding affects many users of combined menopausal hormone therapy (HT) and commonly leads to invasive and expensive investigations to exclude underlying malignancy. In most cases no abnormality is found.\n\nThe main objective of this study was to explore the role of uterine natural killer (uNK) cells and their regulatory cytokine IL-15 in irregular bleeding in HT users.\n\nThis was a prospective observational study conducted between 2002 and 2004.\n\nThe study was conducted in a tertiary referral menopause clinic at King Edward Memorial Hospital, Western Australia.\n\nPatients included 117 postmenopausal women taking combined HT.\n\nOutpatient endometrial biopsies were taken during and outside bleeding episodes.\n\nThe relationship between endometrial uNK cells (CD56+) and bleeding patterns was measured. We also addressed the impact of HT exposure on uNK cell populations, the relationship between endometrial IL-15 expression and uNK cell populations, and killer Ig like receptor genotype in subjects with irregular bleeding.\n\nEndometrial CD56+ uNK cells were significantly increased in biopsies obtained during bleeding episodes (P<0.001), compared with HT users with no bleeding. The highest level of IL-15 expression was also seen in biopsies taken during bleeding. No clear relationship between killer Ig like receptor genotype and bleeding on HT was observed.", "target": "yes", "year": "2005", "labels": ["CONTEXT", "OBJECTIVE", "DESIGN", "SETTING", "PATIENTS", "INTERVENTIONS", "MAIN OUTCOME MEASURES", "RESULTS"]}
{"id": "21394762", "question": "Is pelvic pain associated with defecatory symptoms in women with pelvic organ prolapse?", "context": "To investigate the significance of pelvic pain and its association with defecatory symptoms in women with pelvic organ prolapse (POP).\n\nThis is a cross sectional study of 248 women with stage II POP or greater. Women were stratified into \"pain\" and \"no-pain\" groups based on their response to a question on the Pelvic Floor Distress Inventory short form. Associations between patient demographics, exam findings and responses to validated questionnaires were evaluated.\n\nIn women with POP, defecatory symptoms are significantly more common in women with pelvic pain including straining with bowel movement (OR 2.4, 95% CI 1.3, 4.6), sense of incomplete emptying (OR 4.4, 95% CI 2.3, 8.2), pain with bowel movement (OR 5.3, 95% CI 1.2, 23.0) and splinting with bowel movement (OR 3.8, 95% CI 2.0, 7.5).", "target": "yes", "year": "2011", "labels": ["OBJECTIVE", "STUDY DESIGN", "RESULTS"]}
{"id": "17342562", "question": "The clinical significance of bile duct sludge: is it different from bile duct stones?", "context": "Some patients with suspected common bile duct (CBD) stones are found to have sludge and no stones. Although sludge in the gallbladder is a precursor of gallbladder stones, the significance of bile duct sludge (BDS) is poorly defined. This study aimed to compare BDS with bile duct stones in terms of frequency, associated risk factors, and clinical outcome after endoscopic therapy.\n\nThe study enrolled 228 patients who underwent therapeutic endoscopic retrograde cholangiopancreatography (ERCP) for suspected choledocholithiasis. The patients were divided into two groups: patients with BDS but no stones on ERCP and patients with CBD stones. The presence of risk factors for bile duct stones (age, periampullary diverticulum, ductal dilation or angulation, previous open cholecystectomy) were assessed at ERCP. Follow-up data (36 +/- 19 months) were obtained from medical records and by patient questioning.\n\nBile duct sludge occurred in 14% (31/228) of patients and was more common in females. After endoscopic clearance, CBD stones recurred in 17% (33/197) of the patients with CBD stones, and in 16% (5/31) of the patients with BDS (p = 0.99). Common bile duct dilation was less common in the sludge group. The other known risk factors for recurrent CBD stones (age, previous open cholecystectomy, bile duct angulation, and the presence of a peripampullary diverticulum) were not statistically different between the two groups.", "target": "no", "year": "2007", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "12963175", "question": "Can progression of valvar aortic stenosis be predicted accurately?", "context": "It was the aim of the present study to elaborate criteria for the assessment of rapid hemodynamic progression of valvar aortic stenosis. These criteria are of special importance when cardiac surgery is indicated for other reasons but the established criteria for aortic valve replacement are not yet fulfilled. Such aspects of therapeutic planing were mostly disregarded in the past so that patients had to undergo cardiac reoperation within a few years.\n\nHemodynamic, echocardiographic, and clinical data of 169 men and 88 women with aortic stenosis, aged 55.2 +/- 15.7 years at their first and 63.4 +/- 15.6 years at their second cardiac catheterization, were analyzed.\n\nThe progression rate of aortic valve obstruction was found to be dependent on the degree of valvar calcification ([VC] scoring 0 to III) and to be exponentially correlated with the aortic valve opening area (AVA) at initial catheterization. Neither age nor sex of the patient nor etiology of the valvar obstruction significantly influence the progression of aortic stenosis. If AVA decreases below 0.75 cm(2) with a present degree of VC = 0, or AVA of 0.8 with VC of I, AVA of 0.9 with VC of II, or AVA of 1.0 with VC of III, it is probable that aortic stenosis will have to be operated upon in the following years.", "target": "yes", "year": "2003", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "24669960", "question": "Does the sex of acute stroke patients influence the effectiveness of rt-PA?", "context": "Women have been reported to show more frequent recanalization and better recovery after intravenous (IV) recombinant tissue plasminogen activator (rt-PA) treatment for acute stroke compared with men. To investigate this we studied a series of stroke patients receiving IV rt-PA and undergoing acute transcranial doppler (TCD) examination.\n\nAcute stroke patients received IV rt-PA and had acute TCD examination within 4 hours of symptom onset at 4 major stroke centers. TCD findings were interpreted using the Thrombolysis in Brain Ischemia (TIBI) flow grading system. The recanalization rates, and poor 3-month outcomes (modified Rankin scale>2) of men and women were compared using the chi-square test. Multiple regression analysis was used to assess sex as a predictor of recanalization and poor 3-month outcome after controlling for age, baseline NIH Stroke Scale (NIHSS), time to treatment, hypertension, and blood glucose.\n\n369 patients had TCD examinations before or during IV rt-PA treatment. The 199 (53.9%) men and 170 (46.1%) women had mean ages of 67 ± 13 and 70 ± 14 years, respectively. The sexes did not differ significantly in baseline stroke severity, time to TCD examination, or time to thrombolysis. Of the men, 68 (34.2%) had complete recanalization, 58 (29.1%) had partial recanalization, and 73 (36.6%) had no recanalization. Of the women, 53 (31.2%) had complete recanalization, 46 (27%) had partial recanalization, and 71 (41.8%) had no recanalization (p = 0.6). Multiple regression analyses showed no difference between the sexes in recanalization rate, time to recanalization, or clinical outcome at 3 months.", "target": "no", "year": "2014", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "23072266", "question": "Has the use of complementary and alternative medicine therapies by U.S. adults with chronic disease-related functional limitations changed from 2002 to 2007?", "context": "This study examined changes in the use of complementary and alternative medicine (CAM) therapies by U.S. adults aged 18 years or older with chronic disease-related functional limitations between 2002 and 2007.\n\nThe study was a cross-sectional survey.SETTING/\n\nThe study was conducted in the United States.\n\nThe study comprised adults aged 18 years or older with chronic disease-related functional limitations.\n\nData were obtained from the 2002 and 2007 U.S. National Health Interview Survey to compare the use of 22 CAM therapies (n=9313 and n=7014, respectively). Estimates were age adjusted to the year 2000 U.S. standard population.\n\nThe unadjusted and age-standardized prevalence of overall CAM use (22 therapies comparable between both survey years) was higher in 2007 than in 2002 (30.6% versus 26.9%, p<0.001 and 34.4% versus 30.6%, p<0.001, respectively). Adults with functional limitations that included changing and maintaining body position experienced a significant increase in CAM use between 2002 and 2007 (31.1%-35.0%, p<0.01). The use of deep breathing exercises was the most prevalent CAM therapy in both 2002 and 2007 and increased significantly during this period (from 17.9% to 19.9%, p<0.05). The use of meditation, massage, and yoga also increased significantly from 2002 and 2007 (11.0%-13.5%, p<0.01; 7.0%-10.9%, p<0.0001; and 5.1% to 6.6%, p<0.05, respectively), while the use of the Atkins diet decreased (2.2%- 1.4%, p<0.01).", "target": "yes", "year": "2013", "labels": ["OBJECTIVES", "DESIGN", "LOCATION", "SUBJECTS", "METHODS", "RESULTS"]}
{"id": "26037986", "question": "30-Day and 1-year mortality in emergency general surgery laparotomies: an area of concern and need for improvement?", "context": "Emergency surgery is associated with poorer outcomes and higher mortality with recent studies suggesting the 30-day mortality to be 14-15%. The aim of this study was to analyse the 30-day mortality, age-related 30-day mortality and 1-year mortality following emergency laparotomy. We hope this will encourage prospective data collection, improvement of care and initiate strategies to establish best practice in this area.\n\nThis was a retrospective study of patients who underwent emergency laparotomy from June 2010 to May 2012. The primary end point of the study was 30-day mortality, age-related 30-day mortality and 1-year all-cause mortality.\n\n477 laparotomies were performed in 446 patients. 57% were aged<70 and 43% aged>70 years. 30-day mortality was 12, 4% in those aged<70 years and 22% in those>70 years (p<0.001). 1-year mortality was 25, 15% in those aged under 70 years and 38% in those aged>70 years (p<0.001).", "target": "maybe", "year": "2015", "labels": ["AIMS", "METHODS", "RESULTS"]}
{"id": "27288618", "question": "Is inhaled prophylactic heparin useful for prevention and Management of Pneumonia in ventilated ICU patients?", "context": "To determine whether prophylactic inhaled heparin is effective for the prevention and treatment of pneumonia patients receiving mechanical ventilation (MV) in the intensive care unit.\n\nA phase 2, double blind randomized controlled trial stratified for study center and patient type (non-operative, post-operative) was conducted in three university-affiliated intensive care units. Patients aged ≥18years and requiring invasive MV for more than 48hours were randomized to usual care, nebulization of unfractionated sodium heparin (5000 units in 2mL) or placebo nebulization with 0.9% sodium chloride (2mL) four times daily with the main outcome measures of the development of ventilator associated pneumonia (VAP), ventilator associated complication (VAC) and sequential organ failure assessment scores in patients with pneumonia on admission or who developed VAP.\n\nAustralian and New Zealand Clinical Trials Registry ACTRN12612000038897.\n\nTwo hundred and fourteen patients were enrolled (72 usual care, 71 inhaled sodium heparin, 71 inhaled sodium chloride). There were no differences between treatment groups in terms of the development of VAP, using either Klompas criteria (6-7%, P=1.00) or clinical diagnosis (24-26%, P=0.85). There was no difference in the clinical consistency (P=0.70), number (P=0.28) or the total volume of secretions per day (P=.54). The presence of blood in secretions was significantly less in the usual care group (P=0.005).", "target": "no", "year": "2016", "labels": ["PURPOSE", "METHODS", "TRIAL REGISTRATION", "RESULTS"]}
{"id": "17919952", "question": "Are reports of mechanical dysfunction in chronic oro-facial pain related to somatisation?", "context": "(i) To examine the association between self-reported mechanical factors and chronic oro-facial pain. (ii) To test the hypothesis that this relationship could be explained by: (a) reporting of psychological factors, (b) common association of self-reported mechanical factors with other unexplained syndromes.\n\nA population based cross-sectional study of 4200 randomly selected adults registered with a General Medical Practice in North West, England. The study examined the association of chronic oro-facial pain with a variety of self-reported mechanical factors: teeth grinding, facial trauma, missing teeth and the feeling that the teeth did not fit together properly. Information was also collected on demographic factors, psychological factors and the reporting of other frequently unexplained syndromes.\n\nAn adjusted response rate of 72% was achieved. Only two mechanical factors: teeth grinding (odds ratio (OR) 2.0, 95% CI 1.3-3.0) and facial trauma (OR 2.0; 95% CI 1.3-2.9) were independently associated with chronic oro-facial pain after adjusting for psychological factors. However, these factors were also commonly associated with the reporting of other frequently unexplained syndromes: teeth grinding (odds ratio (OR) 1.8, 95% CI 1.5-2.2), facial trauma (OR 2.1; 95% CI 1.7-2.6).", "target": "yes", "year": "2008", "labels": ["OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "22955530", "question": "Type II supracondylar humerus fractures: can some be treated nonoperatively?", "context": "The range of injury severity that can be seen within the category of type II supracondylar humerus fractures (SCHFs) raises the question whether some could be treated nonoperatively. However, the clinical difficulty in using this approach lies in determining which type II SCHFs can be managed successfully without a surgical intervention.\n\nWe reviewed clinical and radiographic information on 259 pediatric type II SCHFs that were enrolled in a prospective registry of elbow fractures. The characteristics of the patients who were treated without surgery were compared with those of patients who were treated surgically. Treatment outcomes, as assessed by the final clinical and radiographic alignment, range of motion of the elbow, and complications, were compared between the groups to define clinical and radiographic features that related to success or failure of nonoperative management.\n\nDuring the course of treatment, 39 fractures were found to have unsatisfactory alignment with nonoperative management and were taken for surgery. Ultimately, 150 fractures (57.9%) were treated nonoperatively, and 109 fractures (42.1%) were treated surgically. At final follow-up, outcome measures of change in carrying angle, range of motion, and complications did not show clinically significant differences between treatment groups. Fractures without rotational deformity or coronal angulation and with a shaft-condylar angle of>15 degrees were more likely to be associated with successful nonsurgical treatment. A scoring system was developed using these features to stratify the severity of the injury. Patients with isolated extension deformity, but none of the other features, were more likely to complete successful nonoperative management.", "target": "yes", "year": null, "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "22382608", "question": "SPECT study with I-123-Ioflupane (DaTSCAN) in patients with essential tremor. Is there any correlation with Parkinson's disease?", "context": "The differential diagnosis between essential tremor (ET) and Parkinson's disease (PD) may be, in some cases, very difficult on clinical grounds alone. In addition, it is accepted that a small percentage of ET patients presenting symptoms and signs of possible PD may progress finally to a typical pattern of parkinsonism. Ioflupane, N-u-fluoropropyl-2a-carbomethoxy-3a-(4-iodophenyl) nortropane, also called FP-CIT, labelled with (123)I (commercially known as DaTSCAN) has been proven to be useful in the differential diagnosis between PD and ET and to confirm dopaminergic degeneration in patients with parkinsonism. The aim of this study is to identify dopaminergic degeneration in patients with PD and distinguish them from others with ET using semi-quantitative SPECT (123)I-Ioflupane (DaTSCAN) data in comparison with normal volunteers (NV), in addition with the respective ones of patients referred as suffering from ET, as well as, of patients with a PD diagnosis at an initial stage with a unilateral presentation of motor signs.\n\nTwenty-eight patients suffering from ET (10 males plus 18 females) and 28 NV (12 males and 16 females) were enroled in this study. In addition, 33 patients (11 males and 22 females) with an established diagnosis of PD with unilateral limb involvement (12 left hemi-body and 21 right hemi-body) were included for comparison with ET. We used DaTSCAN to obtain SPECT images and measure the radiopharmaceutical uptake in the striatum (S), as well as the caudate nucleus (CN) and putamen (P) in all individuals.\n\nQualitative (Visual) interpretation of the SPECT data did not find any difference in the uptake of the radiopharmaceutical at the level of the S, CN and P between NV and ET patients. Reduced accumulation of the radiopharmaceutical uptake was found in the P of all PD patients. Semiquantitative analysis revealed significant differences between NV and ET patients in the striatum, reduced in the latter. There was also a significant reduction in the tracer accumulation in the left putamen of patients with right hemi-parkinsonism compared to ET and NV. Patients with left hemi-parkinsonism, demonstrated reduced radioligand uptake in the right putamen in comparison with ET and NV. Clinical follow-up of 20 patients with ET at (so many months afterwards) revealed no significant change in clinical presentation, particularly no signs of PD. Follow-up DaTSCAN performed in 10 of them (so many months afterwards) was negative in all but one. This one had an equivocal baseline study which deteriorated 12 months later.", "target": "no", "year": "2012", "labels": ["OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "24153338", "question": "Is aneurysm repair justified for the patients aged 80 or older after aneurysmal subarachnoid hemorrhage?", "context": "With the advancement of an aging society in the world, an increasing number of elderly patients have been hospitalized due to aneurysmal subarachnoid hemorrhage (aSAH). There is no study that compares the elderly cases of aSAH who receive the definitive treatment with those who treated conservatively. The aim of this study was to investigate the feasibility of the definitive surgery for the acute subarachnoid cases aged 80 or older.\n\nWe reviewed 500 consecutive cases with acute aSAH with surgical indication for aneurysm repair. Inoperable cases such as dead-on-arrival and the cases with both pupils dilated were excluded. We compared the cases aged 80 or older that received clipping or coil embolization with the controls that the family selected conservative treatment.\n\n69 cases were included in this study (ranged 80-98, male:female=9:60). 56 cases (81.2%) had an aneurysm in the anterior circulation. 23 cases received clipping, 20 cases coil embolization and 26 cases treated conservatively. The cases with aneurysm repair showed significantly better clinical outcome than the controls, while World Federation of Neurological Surgeons (WFNS) grade on admission and premorbid modified Rankin Scale showed no difference between them.", "target": "yes", "year": "2014", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "23149821", "question": "Should HIV-infected patients be screened for silent myocardial ischaemia using gated myocardial perfusion SPECT?", "context": "A higher prevalence of cardiovascular risk factors (CRFs) in HIV-infected patients, together with chronic infection and treatments, has resulted in an increased risk of silent myocardial ischaemia (SMI). The objective of this study was to evaluate whether myocardial SPECT should be used for screening HIV-infected patients with no clinical symptoms of coronary artery disease.\n\nThe prevalence of SMI detected by myocardial SPECT was determined in 94 HIV-infected patients with a normal clinical cardiovascular examination in relation to anthropomorphic parameters, CRFs, inflammatory and HIV infection status, and treatment.\n\nCoronary artery disease was detected in nine patients (eight with ischaemia, one with myocardial infarction), corresponding to 9.6 % positivity. All but two of the scintigraphic diagnoses of ischaemia were confirmed by coronarography. Univariate analysis revealed that the overall number of CRFs and the combination of gender and age were associated with a diagnosis of SMI (p<0.05). According to multivariate analysis, the only independent parameter significantly associated with the scintigraphic diagnosis of SMI was the combination of gender and age (p = 0.01). All the positive myocardial SPECT scans were in men older than 52 years with at least two other CRFs. In this subpopulation of 47 patients, the prevalence of SMI detected by myocardial SPECT reached 19.2 %.", "target": "maybe", "year": "2013", "labels": ["PURPOSE", "METHODS", "RESULTS"]}
{"id": "15879722", "question": "Is cytokeratin immunoreactivity useful in the diagnosis of short-segment Barrett's oesophagus in Korea?", "context": "Cytokeratin 7/20 staining has been reported to be helpful in diagnosing Barrett's oesophagus and gastric intestinal metaplasia. However, this is still a matter of some controversy.\n\nTo determine the diagnostic usefulness of cytokeratin 7/20 immunostaining for short-segment Barrett's oesophagus in Korea.\n\nIn patients with Barrett's oesophagus, diagnosed endoscopically, at least two biopsy specimens were taken from just below the squamocolumnar junction. If goblet cells were found histologically with alcian blue staining, cytokeratin 7/20 immunohistochemical stains were performed. Intestinal metaplasia at the cardia was diagnosed whenever biopsy specimens taken from within 2 cm below the oesophagogastric junction revealed intestinal metaplasia. Barrett's cytokeratin 7/20 pattern was defined as cytokeratin 20 positivity in only the superficial gland, combined with cytokeratin 7 positivity in both the superficial and deep glands.\n\nBarrett's cytokeratin 7/20 pattern was observed in 28 out of 36 cases (77.8%) with short-segment Barrett's oesophagus, 11 out of 28 cases (39.3%) with intestinal metaplasia at the cardia, and nine out of 61 cases (14.8%) with gastric intestinal metaplasia. The sensitivity and specificity of Barrett's cytokeratin 7/20 pattern were 77.8 and 77.5%, respectively.", "target": "yes", "year": "2005", "labels": ["BACKGROUND", "OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "23412195", "question": "Should displaced midshaft clavicular fractures be treated surgically?", "context": "This study was designed to compare clinical effectiveness of operative with nonoperative treatment for displaced midshaft clavicular fractures (DMCF).\n\nWe systematically searched electronic databases (MEDILINE, EMBASE, CLINICAL, OVID, BIOSIS and Cochrane registry of controlled clinical trials) to identify randomized controlled trials (RCTs) in which operative treatment was compared with nonoperative treatment for DMCF from 1980 to 2012. The methodologic quality of trials was assessed. Data from chosen studies were pooled with using of fixed-effects and random-effects models with mean differences and risk ratios for continuous and dichotomous variables, respectively.\n\nFour RCTs with a total of 321 patients were screened for the present study. Results showed that the operative treatment was superior to the nonoperative treatment regarding the rate of nonunion [95 % confidence interval (CI) (0.05, 0.43), P = 0.0004], malunion [95 % CI (0.06, 0.34), P < 0.00001] and overall complication [95 % CI (0.43-0.76), P = 0.0001]. Subgroup analyses of complications revealed that significant differences were existed in the incidence of neurologic symptoms [95 % CI (0.20, 0.74), P = 0.004] and dissatisfaction with appearance [95 % CI (0.19, 0.65), P = 0.001]. Lack of consistent and standardized assessment data, insufficiency analysis that carried out showed improved functional outcomes (P < 0.05) in operative treatment.", "target": "yes", "year": "2013", "labels": ["PURPOSE", "METHODS", "RESULTS"]}
{"id": "21669959", "question": "Secondhand smoke risk in infants discharged from an NICU: potential for significant health disparities?", "context": "Secondhand smoke exposure (SHSe) threatens fragile infants discharged from a neonatal intensive care unit (NICU). Smoking practices were examined in families with a high respiratory risk infant (born at very low birth weight; ventilated>12 hr) in a Houston, Texas, NICU. Socioeconomic status, race, and mental health status were hypothesized to be related to SHSe and household smoking bans.\n\nData were collected as part of The Baby's Breath Project, a hospital-based SHSe intervention trial targeting parents with a high-risk infant in the NICU who reported a smoker in the household (N = 99). Measures of sociodemographics, smoking, home and car smoking bans, and depression were collected.\n\nOverall, 26% of all families with a high-risk infant in the NICU reported a household smoker. Almost half of the families with a smoker reported an annual income of less than $25,000. 46.2% of families reported having a total smoking ban in place in both their homes and cars. Only 27.8% families earning less than $25,000 reported having a total smoking ban in place relative to almost 60% of families earning more (p<.01). African American and Caucasian families were less likely to have a smoking ban compared with Hispanics (p<.05). Mothers who reported no smoking ban were more depressed than those who had a household smoking ban (p<.02).", "target": "yes", "year": "2011", "labels": ["INTRODUCTION", "METHODS", "RESULTS"]}
{"id": "26200172", "question": "Can biofeedback training of psychophysiological responses enhance athletes' sport performance?", "context": "In recent years, biofeedback has become increasingly popular for its proven success in peak performance training - the psychophysiological preparation of athletes for high-stakes sport competitions, such as the Olympic games. The aim of this research was to test whether an 8-week period of exposure to biofeedback training could improve the psychophysiological control over competitive anxiety and enhance athletic performance in participating subjects.\n\nParticipants of this study were highly competent athletes, each training in different sport disciplines. The experimental group consisted of 18 athletes (4 women, 14 men), whereas the Control group had 21 athletes (4 women, 17 men). All athletes were between 16 and 34 years old. The biofeedback device, Nexus 10, was used to detect and measure the psychophysiological responses of athletes. Athletes from both groups (control and experimental) were subjected to stress tests at the beginning of the study and once again at its conclusion. In between, the experimental group received training in biofeedback techniques. We then calculated the overall percentage of athletes in the experimental group compared with those in the control group who were able to control respiration, skin conductance, heart rate, blood flow amplitude, heart rate variability, and heart respiration coherence. One year following completion of the initial study, we questioned athletes from the experimental group, to determine whether they continued to use these skills and if they could detect any subsequent enhancement in their athletic performance.\n\nWe demonstrated that a greater number of participants in the experimental group were able to successfully control their psychophysiological parameters, in comparison to their peers in the control group. Significant results (p<0.05) were noted in regulation of GSR following short stress test conditions (p = 0.037), in regulation of HR after exposure to STROOP stressor (p = 0.037), in regulation of GSR following the Math and GSR stressors (p = 0.033, p = 0.409) and in achieving HR - breathing coherence following the math stressor (p = 0.042).", "target": "yes", "year": "2015", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "27448572", "question": "Is duration of psychological treatment for depression related to return into treatment?", "context": "There is increasing pressure on mental health providers to reduce the duration of treatments, while retaining level of quality and effectiveness. The risk is that the population is underserved and therefore needs new treatment episodes. The primary aim of this study was to investigate whether duration of treatment and return into mental health care were related.\n\nThis study examined Dutch patients with an initial treatment episode in 2009 or 2010 in specialized mental health settings for depressive disorder (N = 85,754). Follow-up data about treatment episodes were available up until 2013. The data set included demographic (age, gender), and clinical factors (comorbidity with other DSM-IV Axis; scores on the 'Global Assessment of Functioning'). Cox regression analyses were used to assess whether duration of treatment and relapse into mental health care were related.\n\nThe majority of patients did not return into mental health care (86 %). Patients with a shorter duration of treatment (5-250 min; 251-500 min and 751-1000 min) were slightly more likely to return (reference group:>1000 min) (HR 1.19 95 % CI 1.13-1.26; HR 1.11 95 % CI 1.06-1.17; HR 1.18 95 % CI 1.11-1.25), adjusted for demographic and clinical variables.", "target": "yes", "year": "2016", "labels": ["PURPOSE", "METHODS", "RESULTS"]}
{"id": "23002947", "question": "Does feeding tube insertion and its timing improve survival?", "context": "To examine survival with and without a percutaneous endoscopic gastrostomy (PEG) feeding tube using rigorous methods to account for selection bias and to examine whether the timing of feeding tube insertion affected survival.\n\nProspective cohort study.\n\nAll U.S. nursing homes (NHs).\n\nThirty-six thousand four hundred ninety-two NH residents with advanced cognitive impairment from dementia and new problems eating studied between 1999 and 2007.\n\nSurvival after development of the need for eating assistance and feeding tube insertion.\n\nOf the 36,492 NH residents (88.4% white, mean age 84.9, 87.4% with one feeding tube risk factor), 1,957 (5.4%) had a feeding tube inserted within 1 year of developing eating problems. After multivariate analysis correcting for selection bias with propensity score weights, no difference was found in survival between the two groups (adjusted hazard ratio (AHR) = 1.03, 95% confidence interval (CI) = 0.94-1.13). In residents who were tube-fed, the timing of PEG tube insertion relative to the onset of eating problems was not associated with survival after feeding tube insertion (AHR = 1.01, 95% CI = 0.86-1.20, persons with a PEG tube inserted within 1 month of developing an eating problem versus later (4 months) insertion).", "target": "no", "year": "2012", "labels": ["OBJECTIVES", "DESIGN", "SETTING", "PARTICIPANTS", "MEASUREMENTS", "RESULTS"]}
{"id": "18568239", "question": "Is the ability to perform transurethral resection of the prostate influenced by the surgeon's previous experience?", "context": "To evaluate the influence of the urologist's experience on the surgical results and complications of transurethral resection of the prostate (TURP).\n\nSixty-seven patients undergoing transurethral resection of the prostate without the use of a video camera were randomly allocated into three groups according to the urologist's experience: a urologist having done 25 transurethral resections of the prostate (Group I - 24 patients); a urologist having done 50 transurethral resections of the prostate (Group II - 24 patients); a senior urologist with vast transurethral resection of the prostate experience (Group III - 19 patients). The following were recorded: the weight of resected tissue, the duration of the resection procedure, the volume of irrigation used, the amount of irrigation absorbed and the hemoglobin and sodium levels in the serum during the procedure.\n\nThere were no differences between the groups in the amount of irrigation fluid used per operation, the amount of irrigation fluid absorbed or hematocrit and hemoglobin variation during the procedure. The weight of resected tissue per minute was approximately four times higher in group III than in groups I and II. The mean absorbed irrigation fluid was similar between the groups, with no statistical difference between them (p=0.24). Four patients (6%) presented with TUR syndrome, without a significant difference between the groups.", "target": "yes", "year": "2008", "labels": ["PURPOSE", "PATIENTS AND METHODS", "RESULTS"]}
{"id": "14872327", "question": "Is pain a clinically relevant problem in general adult psychiatry?", "context": "To study the prevalence of pain and risk factors for pain in psychiatric patients in a psychiatric hospital.\n\nUsing a questionnaire we investigated in a cross-sectional study the prevalence of pain, duration of pain, impairment and unfitness for work due to pain in 106 patients primarily diagnosed with a psychiatric disorder in the field of general adult psychiatry. Potential risk factors were explored.\n\nThe point prevalence of pain was about 50%, the 6-month prevalence 75.5% and the 12-month prevalence 76.5%. The patients' most frequent complaints were low back pain, headache and shoulder and neck pain. Patients with affective disorders most frequently had pain complaints, followed by those with neurotic, stress-related and somatoform disorders and those with psychotic disorders such as schizophrenia, schizotypic and delusional disorders. Almost 10% of all patients reported pain continuing at least 3 months in the past year. Impairment and unfitness for work were related to specific psychiatric diagnosis. Statistically significant risk factors for pain were depression (OR=6.05) and the number of past admissions to psychiatric hospitals (OR=3.609).", "target": "yes", "year": "2004", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "20594006", "question": "A patient with myelomeningocele: is untethering necessary prior to scoliosis correction?", "context": "Tethering of the spinal cord is thought to increase the chance of neurological injury when scoliosis correction is undertaken. All patients with myelomeningocele (MM) are radiographically tethered, and untethering procedures carry significant morbidity risks including worsening neurological function and wound complications. No guidelines exist as regards untethering in patients with MM prior to scoliosis correction surgery. The authors' aim in this study was to evaluate their experience in patients with MM who were not untethered before scoliosis correction.\n\nSeventeen patients with MM were retrospectively identified and 1) had no evidence of a clinically symptomatic tethered cord, 2) had undergone spinal fusion for scoliosis correction, and 3) had not been untethered for at least 1 year prior to surgery. The minimum follow-up after fusion was 2 years. Charts and radiographs were reviewed for neurological or shunt complications in the perioperative period.\n\nThe average age of the patients was 12.4 years, and the following neurological levels were affected: T-12 and above, 7 patients; L-1/L-2, 6 patients; L-3, 2 patients; and L-4, 2 patients. All were radiographically tethered as confirmed on MR imaging. Fourteen of the patients (82%) had a ventriculoperitoneal shunt. The mean Cobb angle was corrected from 82 degrees to 35 degrees , for a 57% correction. All patients underwent neuromonitoring of their upper extremities, and some underwent lower extremity monitoring as well. Postoperatively, no patient experienced a new cranial nerve palsy, shunt malfunction, change in urological function, or upper extremity weakness/sensory loss. One patient had transient lower extremity weakness, which returned to baseline within 1 month of surgery.", "target": "no", "year": "2010", "labels": ["OBJECT", "METHODS", "RESULTS"]}
{"id": "22491528", "question": "Combining process indicators to evaluate quality of care for surgical patients with colorectal cancer: are scores consistent with short-term outcome?", "context": "To determine if composite measures based on process indicators are consistent with short-term outcome indicators in surgical colorectal cancer care.\n\nLongitudinal analysis of consistency between composite measures based on process indicators and outcome indicators for 85 Dutch hospitals.\n\nThe Dutch Surgical Colorectal Audit database, the Netherlands.\n\n4732 elective patients with colon carcinoma and 2239 with rectum carcinoma treated in 85 hospitals were included in the analyses.\n\nAll available process indicators were aggregated into five different composite measures. The association of the different composite measures with risk-adjusted postoperative mortality and morbidity was analysed at the patient and hospital level.\n\nAt the patient level, only one of the composite measures was negatively associated with morbidity for rectum carcinoma. At the hospital level, a strong negative association was found between composite measures and hospital mortality and morbidity rates for rectum carcinoma (p<0.05), and hospital morbidity rates for colon carcinoma.", "target": "maybe", "year": "2012", "labels": ["OBJECTIVE", "DESIGN", "SETTING", "PARTICIPANTS", "MAIN OUTCOME MEASURES", "RESULTS"]}
{"id": "10340286", "question": "Is there a role for leukocyte and CRP measurements in the diagnosis of acute appendicitis in the elderly?", "context": "The diagnosis of acute appendicitis is still difficult and the results are unsatisfactory in three particular patient groups: in children, in fertile-age women and in elderly patients. As our population ages, the challenge for expedient diagnosis and intervention in older age groups will become more and more significant. The present study aimed at clarifying the role of leukocyte count and C-reactive protein (CRP) measurements in the diagnosis of acute appendicitis in the elderly. In particular, are there patients with acute appendicitis but unelevated leukocyte count and CRP?\n\nEighty-three consecutive elderly patients underwent appendectomy for suspected acute appendicitis. The mean leukocyte count and CRP value were calculated in patients with an uninflamed appendix (group A) and in those with acute appendicitis (group B). The percentages of patients with: (1) both values unelevated; (2) only leukocyte count elevated; (3) only CRP value elevated; (4) both values elevated were calculated within the groups A and B.\n\nThere was no statistically significant difference in leukocyte counts or CRP values between patients with an uninflamed appendix (group A) and those with acute appendicitis (group B). When the patients were divided into the four subgroups, the most conspicuous finding was that group B (acute appendicitis, n = 73) contained no patients with both values unelevated.", "target": "maybe", "year": "1999", "labels": ["OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "23448747", "question": "Do older adults with cancer fall more often?", "context": "To examine whether a history of cancer increased the likelihood of a fall in community-dwelling older adults, and if cancer type, stage, or time since diagnosis increased falls.\n\nA longitudinal, retrospective, cohort study.\n\nA home- and community-based waiver program in Michigan.\n\n862 older adults aged 65 years or older with cancer compared to 8,617 older adults without cancer using data from the Minimum Data Set-Home Care and Michigan cancer registry.\n\nReports of falls were examined for 90-180 days. Generalized estimating equations were used to compare differences between the groups.\n\nCancer, falls, patient characteristics, comorbidities, medications, pain, weight loss, vision, memory recall, and activities, as well as cancer type, stage, and time since diagnosis.\n\nA fall occurred at a rate of 33% in older adults with cancer compared to 29% without cancer (p<0.00). Those with a history of cancer were more likely to fall than those without cancer (adjusted odds ratio 1.16; 95% confidence interval [1.02, 1.33]; p = 0.03). No differences in fall rates were determined by cancer type or stage, and the odds of a fall did not increase when adding time since cancer diagnosis.", "target": "yes", "year": "2013", "labels": ["OBJECTIVES", "DESIGN", "SETTING", "SAMPLE", "METHODS", "MAIN RESEARCH VARIABLES", "FINDINGS"]}
{"id": "8375607", "question": "Is the breast best for children with a family history of atopy?", "context": "Previous studies reported that breast-feeding protects children against a variety of diseases, but these studies were generally conducted on \"high-risk\" or hospitalized children. This paper describes the results of our study on the effects of breast-feeding on rate of illness in normal children with a family history of atopy.\n\nA historic cohort approach of 794 children with a family history of atopy was used to assess the effects of breast-feeding on illness rates. Family history of atopy was based on allergic diseases in family members as registered by the family physician. Illness data from birth onwards were available from the Continuous Morbidity Registration of the Department of Family Medicine. Information on breast-feeding was collected by postal questionnaire. We then compared rates of illness between children with a family history of atopy who were and who were not breast-fed.\n\nBreast-feeding was related to lower levels of childhood illness both in the first and the first three years of life. In the first year of life they had fewer episodes of gastroenteritis, lower respiratory tract infections, and digestive tract disorders. Over the next three years of life they had fewer respiratory tract infections and skin infections.", "target": "yes", "year": null, "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "25280365", "question": "Reporting and interpreting red blood cell morphology: is there discordance between clinical pathologists and clinicians?", "context": "Clinical pathologists (CPs) report RBC morphologic (RBC-M) changes to assist clinicians in prioritizing differential diagnoses. However, reporting is subjective, semiquantitative, and potentially biased. Reporting decisions vary among CPs, and reports may not be interpreted by clinicians as intended.\n\nThe aims of this study were to survey clinicians and CPs about RBC-M terms and their clinical value, and identify areas of agreement and discordance.\n\nOnline surveys were distributed to small animal clinicians via the Veterinary Information Network and to CPs via the ASVCP listserv. A quiz assessed understanding of RBC-M terms among respondent groups. Descriptive statistics were used to analyze responses to survey questions, and quiz scores were compared among groups.\n\nAnalyzable responses were obtained from 1662 clinicians and 82 CPs. Both clinicians and CPs considered some terms, e.g., agglutination, useful, whereas only CPs considered other terms, e.g., ghost cells, useful. All groups interpreted certain terms, e.g., Heinz bodies, correctly, whereas some clinicians misinterpreted others, e.g., eccentrocytes. Responses revealed that CPs often do not report RBC-M they consider insignificant, when present in low numbers. Twenty-eight percent of clinicians think CPs review all blood smears while only 19% of CPs report reviewing all smears.", "target": "yes", "year": "2014", "labels": ["BACKGROUND", "OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "24785562", "question": "Is dexamethasone an effective alternative to oral prednisone in the treatment of pediatric asthma exacerbations?", "context": "A short course of systemic corticosteroids is an important therapy in the treatment of pediatric asthma exacerbations. Although a 5-day course of oral prednisone or prednisolone has become the most commonly used regimen, dexamethasone has also been used for a shorter duration (1-2 days) with potential for improvement in compliance and palatability. We reviewed the literature to determine if there is sufficient evidence that dexamethasone can be used as an effective alternative in the treatment of pediatric asthma exacerbations in the inpatient setting.\n\nA Medline search was conducted on the use of dexamethasone in the treatment of asthma exacerbations in children. The studies selected were clinical trials comparing the efficacy of dexamethasone with prednisone. Meta-analysis was performed examining physician revisitation rates and symptomatic return to baseline.\n\nSix completed pediatric clinical trials met the inclusion criteria. All of the pediatric trials found that prednisone is not superior to dexamethasone in treating mild to moderate asthma exacerbations. Meta-analysis demonstrated homogeneity between the dexamethasone and prednisone groups when examining symptomatic return to baseline and unplanned physician revisits after the initial emergency department encounter. Some studies found potential additional benefits of dexamethasone, including improved compliance and less vomiting.", "target": "yes", "year": "2014", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "22720085", "question": "Does insulin resistance drive the association between hyperglycemia and cardiovascular risk?", "context": "Several studies have shown associations between hyperglycemia and risk of cardiovascular disease (CVD) and mortality, yet glucose-lowering treatment does little to mitigate this risk. We examined whether associations between hyperglycemia and CVD risk were explained by underlying insulin resistance.\n\nIn 60 middle-aged individuals without diabetes we studied the associations of fasting plasma glucose, 2-hour post oral glucose tolerance test plasma glucose, insulin sensitivity as well as body fat percentage with CVD risk. Insulin sensitivity was measured as the glucose infusion rate during a euglycemic hyperinsulinemic clamp, body fat percentage was measured by dual X-ray absorptiometry, and CVD risk was estimated using the Framingham risk score. Associations of fasting plasma glucose, 2-hour plasma glucose, insulin sensitivity and body fat percentage with the Framingham risk score were assessed in linear regression models.\n\nBoth fasting and 2-hour plasma glucose levels were associated with higher Framingham risk score (fasting glucose: r(2) = 0.21; 2-hour glucose: r(2) = 0.24; P<0.001 for both), and insulin sensitivity with lower Framingham risk score (r(2) = 0.36; P<0.001). However, adjustment for insulin sensitivity and 2-hour glucose made the effect of fasting glucose non-significant (P = 0.060). Likewise, when adjusting for insulin sensitivity and fasting glucose, the association between 2-hour glucose and Framingham risk score disappeared (P = 0.143). In contrast, insulin sensitivity was still associated with Framingham risk score after adjusting for glucose levels (P<0.001). Body fat was not associated with Framingham risk score when taking insulin sensitivity into account (P = 0.550).", "target": "yes", "year": "2012", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "23587089", "question": "School food policy at Dutch primary schools: room for improvement?", "context": "Schools can play an important role in the prevention of obesity, e.g. by providing an environment that stimulates healthy eating habits and by developing a food policy to provide such an environment. The effectiveness of a school food policy is affected by the content of the policy, its implementation and its support by parents, teachers and principals. The aim of this study is to detect opportunities to improve the school food policy and/or implementation at Dutch primary schools. Therefore, this study explores the school food policy and investigates schools' (teachers and principals) and parents' opinion on the school food policy.\n\nData on the schools' perspective of the food policy was collected from principals and teachers by means of semi-structured interviews. In total 74 principals and 72 teachers from 83 Dutch primary schools were interviewed. Data on parental perceptions about the school food policy were based on a cross-sectional survey among 1,429 parents from the same schools.\n\nMost principals (87.1%) reported that their school had a written food policy; however in most cases the rules were not clearly defined. Most of the principals (87.8%) believed that their school paid sufficient attention to nutrition and health. Teachers and principals felt that parents were primarily responsible to encourage healthy eating habits among children, while 49.8% of the parents believed that it is also a responsibility of the school to foster healthy eating habits among children. Most parents reported that they appreciated the school food policy and comply with the food rules. Parents' opinion on the enforcement of the school food policy varied: 28.1% believed that the school should enforce the policy more strongly, 32.1% was satisfied, and 39.8% had no opinion on this topic.", "target": "yes", "year": "2013", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "27615402", "question": "Does the familial transmission of drinking patterns persist into young adulthood?", "context": "Parental drinking has been shown to be associated with offspring drinking. However, the relationship appears to be more complex than often assumed and few studies have tracked it over longer time periods.\n\nTo explore the long-term (10-year) transmission of familial drinking during adolescence to offspring drinking patterns in young adulthood.\n\nSwedish longitudinal study, assessing the relationship between familial drinking in 2000 and offspring drinking in 2010 using simultaneous quantile regression analysis (n=744).DATA: Data on familial drinking was gathered from the Swedish level-of-living surveys (LNU) and from partner LNU in 2000 while data on offspring drinking in young adulthood was gathered from LNU 2010. Drinking among offspring, parents and potential stepparents was measured through identical quantity-frequency indices referring to the past 12 months in 2010 and 2000 respectively.\n\nYoung adults whose families were abstainers in 2000 drank substantially less across quintiles in 2010 than offspring of non-abstaining families. The difference, however, was not statistically significant between quintiles of the conditional distribution. Actual drinking levels in drinking families were not at all or weakly associated with drinking in offspring. Supplementary analyses confirmed these patterns.", "target": "maybe", "year": "2016", "labels": ["BACKGROUND", "AIMS", "DESIGN", "RESULTS"]}
{"id": "9107172", "question": "Bridge experience with long-term implantable left ventricular assist devices. Are they an alternative to transplantation?", "context": "If long-term use of left ventricular assist devices (LVADs) as bridges to transplantation is successful, the issue of permanent device implantation in lieu of transplantation could be addressed through the creation of appropriately designed trials. Our medium-term experience with both pneumatically and electrically powered ThermoCardiosystems LVADs is presented to outline the benefits and limitations of device support in lieu of transplantation.\n\nDetailed records were kept prospectively for all patients undergoing LVAD insertion. Fifty-eight LVADs were inserted over 5 years, with a survival rate of 74%. Mean patient age was 50 years, and duration of support averaged 98 days. Although common, both preexisting infection and infection during LVAD support were not associated with increased mortality or decreased rate of successful transplantation. Thromboembolic complications were rare, occurring in only three patients (5%) despite the absence of anticoagulation. Ventricular arrhythmias were well tolerated in all patients except in cases of early perioperative right ventricular failure, with no deaths. Right ventricular failure occurred in one third of patients and was managed in a small percentage by right ventricular assist device (RVAD) support and/or inhaled nitric oxide therapy. There were no serious device malfunctions, but five graft-related hemorrhages resulted in two deaths. Finally, a variety of noncardiac surgical procedures were performed in LVAD recipients, with no major morbidity and mortality.", "target": "yes", "year": "1997", "labels": ["BACKGROUND", "METHODS AND RESULTS"]}
{"id": "7547656", "question": "Does continuous intravenous infusion of low-concentration epinephrine impair uterine blood flow in pregnant ewes?", "context": "Bolus intravenous injection of epinephrine can decrease uterine blood flow. This study examined the effects of intravenous infusion of epinephrine on uterine blood flow in the gravid ewe.\n\nMaternal and fetal vascular catheters and a maternal electromagnetic uterine artery flow probe were implanted in 10 near-term gravid ewes. After recovery, saline, 0.125% bupivacaine, 0.125% bupivacaine with 1:200,000 epinephrine, 0.125% bupivacaine with 1:400,000 epinephrine, and 0.125% bupivacaine with 1:800,000 epinephrine were infused into the maternal superior vena cava. Drugs were infused at 10 mL/h for 30 minutes and then at 20 mL/h for an additional 30 minutes. Animals also received an intravenous bolus of epinephrine 15 micrograms. Throughout all infusions, maternal heart rate, systemic and pulmonary blood pressures, uterine blood flow, cardiac output, and acid-base balance were measured, as well as fetal heart rate, blood pressure, and acid-base balance.\n\nEpinephrine 15 micrograms decreased uterine blood flow to 68 +/- 14% of baseline (mean +/- SD). Infusion of all solutions had no effect on any measured hemodynamic variable.", "target": "no", "year": null, "labels": ["BACKGROUND AND OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "17483607", "question": "Does topical N-acetylcysteine application after myringotomy cause severe otorrhea?", "context": "The effect of topical N-acetylcysteine (NAC) application was investigated on the healing of acute experimental tympanic membrane perforations.\n\nTwenty guinea pigs were used in this study. Under intraperitoneal ketamine anesthesia, incisional myringotomies were performed in the posterosuperior quadrant of the tympanic membranes with a straight otologic hook. The diameter of the perforations was approximately 2 mm. Perforations in both ears were treated with freshly prepared sponges soaked in either 0.1 ml 0.9% NaCl solution (10 control animals) or 0.6 mg/0.1 ml NAC (10 animals) for three consecutive days. All the tympanic membranes were examined by otomicroscopy on the third, fifth, seventh, and ninth days.\n\nIn the control group, all the perforations were completely closed at the end of nine days. During the same period, only 40% of the perforations were completely closed in the NAC group. The remaining ears exhibited otorrhea by the third day.", "target": "yes", "year": "2007", "labels": ["OBJECTIVES", "MATERIALS AND METHODS", "RESULTS"]}
{"id": "19482903", "question": "Treadmill testing of children who have spina bifida and are ambulatory: does peak oxygen uptake reflect maximum oxygen uptake?", "context": "Earlier studies have demonstrated low peak oxygen uptake ((.)Vo(2)peak) in children with spina bifida. Low peak heart rate and low peak respiratory exchange ratio in these studies raised questions regarding the true maximal character of (.)Vo(2)peak values obtained with treadmill testing.\n\nThe aim of this study was to determine whether the Vo(2)peak measured during an incremental treadmill test is a true reflection of the maximum oxygen uptake ((.)Vo(2)max) in children who have spina bifida and are ambulatory.\n\nA cross-sectional design was used for this study.\n\nTwenty children who had spina bifida and were ambulatory participated. The (.)Vo(2)peak was measured during a graded treadmill exercise test. The validity of (.)Vo(2)peak measurements was evaluated by use of previously described guidelines for maximum exercise testing in children who are healthy, as well as differences between Vo(2)peak and (.)Vo(2) during a supramaximal protocol ((.)Vo(2)supramaximal).\n\nThe average values for (.)Vo(2)peak and normalized (.)Vo(2)peak were, respectively, 1.23 L/min (SD=0.6) and 34.1 mL/kg/min (SD=8.3). Fifteen children met at least 2 of the 3 previously described criteria; one child failed to meet any criteria. Although there were no significant differences between (.)Vo(2)peak and Vo(2)supramaximal, 5 children did show improvement during supramaximal testing.\n\nThese results apply to children who have spina bifida and are at least community ambulatory.", "target": "yes", "year": "2009", "labels": ["BACKGROUND", "OBJECTIVE", "DESIGN", "METHODS", "RESULTS", "LIMITATIONS"]}
{"id": "25475395", "question": "Is there a correlation between androgens and sexual desire in women?", "context": "For women, the correlation between circulating androgens and sexual desire is inconclusive. Substitution with androgens at physiological levels improves sexual function in women who experience decreased sexual desire and androgen deficiency from surgical menopause, pituitary disease, and age-related decline in androgen production in the ovaries. Measuring bioactive testosterone is difficult and new methods have been proposed, including measuring the primary androgen metabolite androsterone glucuronide (ADT-G).AIM: The aim of this study was to investigate a possible correlation between serum levels of androgens and sexual desire in women and whether the level of ADT-G is better correlated than the level of circulating androgens with sexual desire.\n\nThis was a cross-sectional study including 560 healthy women aged 19-65 years divided into three age groups. Correlations were considered to be statistically significant at P<0.05.\n\nSexual desire was determined as the total score of the sexual desire domain of the Female Sexual Function Index. Total testosterone (TT), calculated free testosterone (FT), androstenedione, dehydroepiandrosterone sulfate (DHEAS), and ADT-G were analyzed using mass spectrometry.\n\nSexual desire correlated overall with FT and androstenedione in the total cohort of women. In a subgroup of women aged 25-44 years with no use of systemic hormonal contraception, sexual desire correlated with TT, FT, androstenedione, and DHEAS. In women aged 45-65 years, androstenedione correlated with sexual desire. No correlations between ADT-G and sexual desire were identified.", "target": "yes", "year": "2015", "labels": ["INTRODUCTION", "METHODS", "MAIN OUTCOME MEASURE", "RESULTS"]}
{"id": "10605400", "question": "Is the international normalised ratio (INR) reliable?", "context": "As part of an MRC funded study into primary care oral anticoagulation management, INR measurements obtained in general practice were validated against values on the same samples obtained in hospital laboratories. A prospective comparative trial was undertaken between three hospital laboratories and nine general practices. All patients attending general practice based anticoagulant clinics had parallel INR estimations performed in general practice and in a hospital laboratory.\n\n405 tests were performed. Comparison between results obtained in the practices and those in the reference hospital laboratory (gold standard), which used the same method of testing for INR, showed a correlation coefficient of 0.96. Correlation coefficients comparing the results with the various standard laboratory techniques ranged from 0.86 to 0.92. It was estimated that up to 53% of tests would have resulted in clinically significant differences (change in warfarin dose) depending upon the site and method of testing. The practice derived results showed a positive bias ranging from 0.28 to 1.55, depending upon the site and method of testing.", "target": "maybe", "year": "1999", "labels": ["METHODS", "RESULTS"]}
{"id": "22521460", "question": "Does route of delivery affect maternal and perinatal outcome in women with eclampsia?", "context": "The route of delivery in eclampsia is controversial. We hypothesized that adverse maternal and perinatal outcomes may not be improved by early cesarean delivery.\n\nThis was a randomized controlled exploratory trial carried out in a rural teaching institution. In all, 200 eclampsia cases, carrying ≥34 weeks, were allocated to either cesarean or vaginal delivery. Composite maternal and perinatal event rates (death and severe morbidity) were compared by intention-to-treat principle.\n\nGroups were comparable at baseline with respect to age and key clinical parameters. Maternal event rate was similar: 10.89% in the cesarean arm vs 7.07% for vaginal delivery (relative risk, 1.54; 95% confidence interval, 0.62-3.81). Although the neonatal event rate was less in cesarean delivery-9.90% vs 19.19% (relative risk, 0.52; 95% confidence interval, 0.25-1.05)-the difference was not significant statistically.", "target": "no", "year": "2012", "labels": ["OBJECTIVE", "STUDY DESIGN", "RESULTS"]}
{"id": "16266387", "question": "Fast foods - are they a risk factor for asthma?", "context": "Lifestyle changes over the last 30 years are the most likely explanation for the increase in allergic disease over this period.AIM: This study tests the hypothesis that the consumption of fast food is related to the prevalence of asthma and allergy.\n\nAs part of the International Study of Asthma and Allergies in Childhood (ISAAC) a cross-sectional prevalence study of 1321 children (mean age = 11.4 years, range: 10.1-12.5) was conducted in Hastings, New Zealand. Using standard questions we collected data on the prevalence of asthma and asthma symptoms, as well as food frequency data. Skin prick tests were performed to common environmental allergens and exercise-induced bronchial hyperresponsiveness (BHR) was assessed according to a standard protocol. Body mass index (BMI) was calculated as weight/height2 (kg/m2) and classified into overweight and obese according to a standard international definition.\n\nAfter adjusting for lifestyle factors, including other diet and BMI variables, compared with children who never ate hamburgers, we found an independent risk of hamburger consumption on having a history of wheeze [consumption less than once a week (OR = 1.44, 95% CI: 1.06-1.96) and 1+ times a week (OR = 1.65, 95% CI: 1.07-2.52)] and on current wheeze [consumption less than once a week (OR = 1.17, 95% CI: 0.80-1.70) and 1+ times a week (OR = 1.81, 95% CI: 1.10-2.98)]. Takeaway consumption 1+ times a week was marginally significantly related to BHR (OR = 2.41, 95% CI: 0.99-5.91). There was no effect on atopy.", "target": "yes", "year": "2005", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "18784527", "question": "Can mandibular depiction be improved by changing the thickness of double-oblique computed tomography images?", "context": "Multislice helical computed tomography (CT), which can provide detailed 2-D and 3-D reconstructed images, is useful in imaging diagnosis for dental implant treatment. Therefore, in this study, it was performed to clarify the mandibular depiction of double-oblique reconstructed images when changing their thickness.\n\nA total of 38 sites in the mandibular molar region were examined using multislice helical CT. The thicknesses of the double-oblique images using multislice helical CT scans were reconstructed in 4 conditions: 0.3 mm, 0.9 mm, 1.6 mm, and 4.1 mm. In double-oblique images, mandibular depiction was evaluated by 5 oral radiologists using a subjective rating score.\n\nIn the alveolar crest and the whole of the mandibular canal, the highest value was obtained with 0.9 mm-thick images; however, there was no significant difference between 0.3 mm and 0.9 mm-thick images.", "target": "no", "year": "2008", "labels": ["PURPOSE", "MATERIALS AND METHODS", "RESULTS"]}
{"id": "16249670", "question": "Does the investing layer of the deep cervical fascia exist?", "context": "The placement of the superficial cervical plexus block has been the subject of controversy. Although the investing cervical fascia has been considered as an impenetrable barrier, clinically, the placement of the block deep or superficial to the fascia provides the same effective anesthesia. The underlying mechanism is unclear. The aim of this study was to investigate the three-dimensional organization of connective tissues in the anterior region of the neck.\n\nUsing a combination of dissection, E12 sheet plastination, and confocal microscopy, fascial structures in the anterior cervical triangle were examined in 10 adult human cadavers.\n\nIn the upper cervical region, the fascia of strap muscles in the middle and the fasciae of the submandibular glands on both sides formed a dumbbell-like fascia sheet that had free lateral margins and did not continue with the sternocleidomastoid fascia. In the lower cervical region, no single connective tissue sheet extended directly between the sternocleidomastoid muscles. The fascial structure deep to platysma in the anterior cervical triangle comprised the strap fascia.", "target": "no", "year": "2005", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "26784147", "question": "Target Serum Urate: Do Gout Patients Know Their Goal?", "context": "To examine gout patients' knowledge of their condition, including the central role of achieving and maintaining the serum urate (SU) goal with the use of urate-lowering therapy (ULT).\n\nThis study of 612 gout patients was conducted at a Veterans Affairs medical center. Gout patients were included based on administrative diagnostic codes and receipt of at least 1 allopurinol prescription over a 1-year period. Questionnaires were mailed to patients and linked to medical records data. The questionnaire included gout-specific knowledge questions, the Patient Activation Measure, and self-reported health outcomes. Knowledge was assessed descriptively. Multivariable logistic regression was used to determine predictors of SU goal knowledge. Associations of knowledge with health outcomes were examined in exploratory analyses.\n\nThe questionnaire had a 62% response rate. Only 14% of patients knew their SU goal, while the majority answered correctly for the other 5 gout-specific knowledge questions. In adjusted analyses, having a rheumatologist as initial prescriber (odds ratio [OR] 3.0 [95% confidence interval (95% CI) 1.4-6.2]) and knowing all of the other 5 gout-specific knowledge questions (OR 2.1 [95% CI 1.3-3.4]) were associated with greater odds of knowing the SU goal. SU goal knowledge was associated with self-reported global health status, but not with self-reported health-related quality of life or gout-specific health status.", "target": "no", "year": "2016", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "18359123", "question": "Is it better to be big?", "context": "Swedish hospital mergers seem to stem from a conviction among policy makers that bigger hospitals lead to lower average costs and improved clinical outcomes. The effects of mergers in the form of multisited hospitals have not been systematically evaluated. The purpose of this article is to contribute to this area of knowledge by exploring responses to the merger of Blekinge Hospital.\n\nThe evaluation was guided by the philosophy of triangulation. A questionnaire was sent to 597 randomly selected employees, that is 24% of the health care staff. Four hundred ninety-eight employees answered the questionnaire, giving a response rate of 83%. Furthermore, interviews of different groups of stakeholders were conducted.\n\nA moderate increase of quality was assessed, which, a low proportion of the employees perceived had decisively or largely to do with the merger. The majority perceives economical incentives as the drivers of change, but, at the same time, only 10% of this group believes this target was reached completely or to a large extent.", "target": "no", "year": "2008", "labels": ["OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "2503176", "question": "Inhibin: a new circulating marker of hydatidiform mole?", "context": "To define the concentrations of inhibin in serum and tissue of patients with hydatidiform mole and assess their value as a clinical marker of the condition.\n\nProspective study of new patients with hydatidiform mole, comparison of paired observations, and case-control analysis.\n\nA university hospital, two large public hospitals, and a private women's clinic in Japan.\n\nSeven consecutive referred patients seen over four months with newly diagnosed complete hydatidiform mole, including one in whom the mole was accompanied by viable twin fetuses (case excluded from statistical analysis because of unique clinical features). All patients followed up for six months after evacuation of molar tissue.\n\nCorrelation of serum inhibin concentrations with trophoblastic disease.\n\nSerum concentrations of inhibin, human chorionic gonadotrophin, and follicle stimulating hormone were compared before and seven to 10 days after evacuation of the mole. Before evacuation the serum inhibin concentrations (median 8.3 U/ml; 95% confidence interval 2.4 to 34.5) were significantly greater than in 21 normal women at the same stage of pregnancy (2.8 U/ml; 2.1 to 3.6), and inhibin in molar tissue was also present in high concentrations (578 U/ml cytosol; 158 to 1162). Seven to 10 days after evacuation inhibin concentrations in serum samples from the same patients declined significantly to values (0.4 U/ml; 0.1 to 1.4) similar to those seen in the follicular phase of normal menstrual cycles. None of the four patients whose serum inhibin concentrations were 0.4 U/ml or less after evacuation developed persistent trophoblastic disease. Though serum human chorionic gonadotrophin concentrations declined after evacuation (6.6 x 10(3) IU/l; 0.8 x 10(3) to 32.6 x 10(3], they remained far higher than in non-pregnant women. Serum follicle stimulating hormone concentrations remained suppressed.", "target": "yes", "year": "1989", "labels": ["OBJECTIVE", "DESIGN", "SETTING", "PATIENTS", "END POINT", "MEASUREMENTS AND MAIN RESULTS"]}
{"id": "27896825", "question": "Is it time to reconsider lobectomy in low-risk paediatric thyroid cancer?", "context": "Current guidelines recommend total thyroidectomy for nearly all children with well-differentiated thyroid cancer (WDTC). These guidelines, however, derive from older data accrued prior to current high-resolution imaging. We speculate that there is a subpopulation of children who may be adequately treated with lobectomy.\n\nRetrospective analysis of prospectively maintained database.\n\nSeventy-three children with WDTC treated between 2004 and 2015.\n\nWe applied two different risk-stratification criteria to this population. First, we determined the number of patients meeting American Thyroid Association (ATA) 'low-risk' criteria, defined as disease grossly confined to the thyroid with either N0/Nx or incidental microscopic N1a disease. Second, we defined a set of 'very-low-risk' histopathological criteria, comprising unifocal tumours ≤4 cm without predefined high-risk factors, and determined the proportion of patients that met these criteria.\n\nTwenty-seven (37%) males and 46 (63%) females were included in this study, with a mean age of 13·4 years. Ipsilateral- and contralateral multifocality were identified in 27 (37·0%) and 19 (26·0%) of specimens. Thirty-seven (51%) patients had lymph node metastasis (N1a = 18/N1b = 19). Pre-operative ultrasound identified all cases with clinically significant nodal disease. Of the 73 patients, 39 (53·4%) met ATA low-risk criteria and 16 (21·9%) met 'very-low-risk' criteria. All 'very-low-risk' patients demonstrated excellent response to initial therapy without persistence/recurrence after a mean follow-up of 36·4 months.", "target": "yes", "year": "2017", "labels": ["OBJECTIVE", "DESIGN", "PATIENTS", "MEASUREMENTS", "RESULTS"]}
{"id": "28177278", "question": "Does spontaneous remission occur in polyarteritis nodosa?", "context": "Polyarteritis nodosa (PAN) is a systemic vasculitis involving mainly medium-sized arteries and, rarely, small-sized arteries. The diagnosis is principally based on clinical exams, biopsy of an affected organ, and/or arteriography of renal or mesenteric arteries. Once diagnosed, immunosuppressive agents, such as glucocorticoids and cyclophosphamide, are generally introduced as soon as possible. Whether spontaneous remission of PAN occurs is therefore largely unknown.\n\nWe describe the case of a 51-year-old woman who presented with a 4-day-history of intense pain in her left flank, hypertension, fever, microscopic hematuria, and acute renal failure. Contrast-enhanced renal ultrasound strongly suggested bilateral renal infarction. Medical history and an extensive workup allowed to exclude systemic embolism, recreational drug abuse, cardiac arrhythmias, and thrombophilia. A possible diagnosis of PAN was considered; however, within 2 weeks of admission, spontaneous remission of her clinical and biological symptoms occurred without the use of any immunosuppressive treatment. Finally, 3 months later, renal arteriography confirmed the diagnosis of PAN. The patient remains free of symptoms 1 year after initial presentation.", "target": "yes", "year": "2017", "labels": ["BACKGROUND", "PRESENTATION"]}
{"id": "20101129", "question": "Is prophylactic fixation a cost-effective method to prevent a future contralateral fragility hip fracture?", "context": ": A previous hip fracture more than doubles the risk of a contralateral hip fracture. Pharmacologic and environmental interventions to prevent hip fracture have documented poor compliance. The purpose of this study was to examine the cost-effectiveness of prophylactic fixation of the uninjured hip to prevent contralateral hip fracture.\n\n: A Markov state-transition model was used to evaluate the cost and quality-adjusted life-years (QALYs) for unilateral fixation of hip fracture alone (including internal fixation or arthroplasty) compared with unilateral fixation and contralateral prophylactic hip fixation performed at the time of hip fracture or unilateral fixation and bilateral hip pad protection. Prophylactic fixation involved placement of a cephalomedullary nail in the uninjured hip and was initially assumed to have a relative risk of a contralateral fracture of 1%. Health states included good health, surgery-related complications requiring a second operation (infection, osteonecrosis, nonunion, and malunion), fracture of the uninjured hip, and death. The primary outcome measure was the incremental cost-effectiveness ratio estimated as cost per QALY gained in 2006 US dollars with incremental cost-effectiveness ratios below $50,000 per QALY gained considered cost-effective. Sensitivity analyses evaluated the impact of patient age, annual mortality and complication rates, intervention effectiveness, utilities, and costs on the value of prophylactic fixation.\n\n: In the baseline analysis, in a 79-year-old woman, prophylactic fixation was not found to be cost-effective (incremental cost-effectiveness ratio = $142,795/QALY). However, prophylactic fixation was found to be a cost-effective method to prevent contralateral hip fracture in: 1) women 71 to 75 years old who had 30% greater relative risk for a contralateral fracture; and 2) women younger than age 70 years. Cost-effectiveness was greater when the additional costs of prophylaxis were less than $6000. However, for most analyses, the success of prophylactic fixation was highly sensitive to the effectiveness and the relative morbidity and mortality of the additional procedure.", "target": "maybe", "year": "2010", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "24519615", "question": "Does patella position influence ligament balancing in total knee arthroplasty?", "context": "In vivo comparative gap measurements were performed in three different patella positions (reduced, subluxated and everted) using offset-type-force-controlled-spreader-system.\n\nProspectively, 50 knees were operated by total knee arthroplasty using a navigation-assisted gap-balancing technique. The offset-type-force-controlled-spreader-system was used for gap measurements. This commercially available instrument allows controllable tension in patella-reduced position. The mediolateral gaps of knee extension (0°) and flexion (90°) angle were recorded in three different patella positions; reduced, subluxated and everted. Any gap differences of more than 3 mm were considered as a meaningful difference. Correlation between the difference with the demographic data, preoperative radiologic alignment and intraoperative data was analysed. For statistical analysis, ANOVA and Pearson's correlation test were used.\n\nThe gaps in patella eversion demonstrated smaller gaps both in knee extension and flexion position compared to the gaps of patella reduction position. The amount of decreased gaps was more definite in knee flexion position. Statistically significant difference was observed for the lateral gap of patella eversion compared to gap of patella reduction in knee flexion position (p<0.05). There were notable cases of variability in knee flexion position. Significant portion of 12 (24 %) knees of patella subluxation and 33 (66 %) knees of patella evertion demonstrated either increased or decreased gaps in knee flexion position compared to the gaps of patella reduction position.", "target": "yes", "year": "2015", "labels": ["PURPOSE", "METHODS", "RESULTS"]}
{"id": "15388567", "question": "Are sports medicine journals relevant and applicable to practitioners and athletes?", "context": "To examine the evidence base of sports medicine research and assess how relevant and applicable it is to everyday practice.\n\nOriginal research articles, short reports, and case reports published in four major sport and exercise medicine journals were studied and classified according to the main topic of study and type of subjects used.\n\nThe most common topic was sports science, and very few studies related to the treatment of injuries and medical conditions. The majority of published articles used healthy subjects sampled from the sedentary population, and few studies have been carried out on injured participants.", "target": "no", "year": "2004", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "11079675", "question": "Pulmonary valve replacement in adults late after repair of tetralogy of fallot: are we operating too late?", "context": "The purpose of this study is to evaluate right ventricular (RV) volume and function after pulmonary valve replacement (PVR) and to address the issue of optimal surgical timing in these patients.\n\nChronic pulmonary regurgitation (PR) following repair of tetralogy of Fallot (TOF) leads to RV dilation and an increased incidence of sudden cardiac death in adult patients.\n\nWe studied 25 consecutive adult patients who underwent PVR for significant PR late after repair of TOF. Radionuclide angiography was performed in all at a mean of 8.2 months (+/- 8 months) before PVR and repeated at a mean of 28.0 months (+/- 22.8 months) after the operation. Right ventricular (RV) end-systolic volume (RVESV), RV end-diastolic volume (RVEDV) and RV ejection fraction (RVEF) were measured.\n\nMean RVEDV, RVESV and RVEF remained unchanged after PVR (227.1 ml versus 214.9 ml, p = 0.74; 157.4 ml versus 155.4 ml, p = 0.94; 35.6% versus 34.7%, p = 0.78, respectively). Of the 10 patients with RVEF>or = 0.40 before PVR, 5 patients (50%) maintained a RVEF>or = 0.40 following PVR, whereas only 2 out of 15 patients (13%) with pre-operative values<0.40 reached an RVEF>or = 0.40 postoperatively (p<0.001).", "target": "yes", "year": "2000", "labels": ["OBJECTIVES", "BACKGROUND", "METHODS", "RESULTS"]}
{"id": "15502995", "question": "Does the early adopter of drugs exist?", "context": "To analyse associations between indicators for adoption of new drugs and to test the hypothesis that physicians' early adoption of new drugs is a personal trait independent of drug groups.\n\nIn a population-based cohort study using register data, we analysed the prescribing of new drugs by Danish general practitioners. Angiotensin-II antagonists, triptans, selective cyclo-oxygenase-2 antagonists and esomeprazol were used in the assessment. As indicators of new drug uptake, we used adoption time, cumulative incidence, preference proportion, incidence rate and prescription cost and volume. For each measure, we ranked the general practices. Ranks were pair-wise plotted, and Pearson's correlation coefficient ( r) was calculated. Next, we analysed the correlation between ranks across different drug classes.\n\nFor all indicators, the general practitioners' adoption of one group of drugs was poorly associated with adoption of others ( r</=0.49), indicating that early adoption of one type of drugs is not associated with early adoption of another. For all drug groups, adoption time adjusted for practice size was only weakly associated with other indicators ( r: -0.56 to -0.27). Indicators, based on cost and volume of drugs, were highly correlated ( r: 0.96-0.99), and the others correlated reasonably well ( r: 0.51-0.91).", "target": "no", "year": "2004", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "16678696", "question": "Continuity of care experience of residents in an academic vascular department: are trainees learning complete surgical care?", "context": "It is widely accepted that exemplary surgical care involves a surgeon's involvement in the preoperative, perioperative, and postoperative periods. In an era of ever-expanding therapeutic modalities available to the vascular surgeon, it is important that trainees gain experience in preoperative decision-making and how this affects a patient's operative and postoperative course. The purpose of this study was to define the current experience of residents on a vascular surgery service regarding the continuity of care they are able to provide for patients and the factors affecting this experience.\n\nThis prospective cohort study was approved by the Institutional Review Board and conducted at the University of British Columbia during January 2005. All patients who underwent a vascular procedure at either of the two teaching hospitals were included. In addition to type of case (emergent, outpatient, inpatient), resident demographic data and involvement in each patient's care (preoperative assessment, postoperative daily assessment, and follow-up clinic assessment) were recorded. Categoric data were analyzed with the chi2 test.\n\nThe study included 159 cases, of which 65% were elective same-day admission patients, 20% were elective previously admitted patients; and 15% were emergent. The overall rate of preoperative assessment was 67%, involvement in the decision to operate, 17%; postoperative assessment on the ward, 79%; and patient follow-up in clinic, 3%. The rate of complete in-hospital continuity of care (assessing patient pre-op and post-op) was 57%. Emergent cases were associated with a significantly higher rate of preoperative assessment (92% vs 63%, P<.05). For elective cases admitted before the day of surgery compared with same-day admission patients, the rates of preoperative assessment (78% vs 58%, P<.05) and involvement in the decision to operate (16% vs 4%, P<.05) were significantly higher.", "target": "no", "year": "2006", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "22497340", "question": "Is horizontal semicircular canal ocular reflex influenced by otolith organs input?", "context": "To clarify whether horizontal canal ocular reflex is influenced by otolith organs input.\n\nThe subjects were seven healthy humans. The right ear was stimulated using ice-water. Each subject was kept in a left-ear-down position for 20 s and then repositioned to a prone position, a right-ear-down position and a supine position with 20 s intervals. Nystagmus was analysed using three-dimensional video-oculography.\n\nEye movements in the supine position and the prone position were not in a symmetric fashion. Nystagmus in the left-ear-down position and the right-ear-down position were not symmetric either. These phenomena indicate that the axis of the eyeball rotation was affected by the shift of the direction of gravity exerted on the head.", "target": "yes", "year": "2012", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "26044262", "question": "Are income-related differences in active travel associated with physical environmental characteristics?", "context": "Rates of active travel vary by socio-economic position, with higher rates generally observed among less affluent populations. Aspects of both social and built environments have been shown to affect active travel, but little research has explored the influence of physical environmental characteristics, and less has examined whether physical environment affects socio-economic inequality in active travel. This study explored income-related differences in active travel in relation to multiple physical environmental characteristics including air pollution, climate and levels of green space, in urban areas across England. We hypothesised that any gradient in the relationship between income and active travel would be least pronounced in the least physically environmentally-deprived areas where higher income populations may be more likely to choose active transport as a means of travel.\n\nAdults aged 16+ living in urban areas (n = 20,146) were selected from the 2002 and 2003 waves of the UK National Travel Survey. The mode of all short non-recreational trips undertaken by the sample was identified (n = 205,673). Three-level binary logistic regression models were used to explore how associations between the trip being active (by bike/walking) and three income groups, varied by level of multiple physical environmental deprivation.\n\nLikelihood of making an active trip among the lowest income group appeared unaffected by physical environmental deprivation; 15.4% of their non-recreational trips were active in both the least and most environmentally-deprived areas. The income-related gradient in making active trips remained steep in the least environmentally-deprived areas because those in the highest income groups were markedly less likely to choose active travel when physical environment was 'good', compared to those on the lowest incomes (OR = 0.44, 95% CI = 0.22 to 0.89).", "target": "no", "year": "2015", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "18403945", "question": "Does laparoscopic antireflux surgery improve quality of life in patients whose gastro-oesophageal reflux disease is well controlled with medical therapy?", "context": "Both medical therapy and laparoscopic antireflux surgery have been shown to improve quality of life in gastro-oesophageal reflux disease. Although patients with poor symptom control or side effects on medical therapy might be expected to have improved quality of life after surgery, our aim was to determine, for the first time, whether patients whose symptoms are well controlled on medical therapy but who decide to undergo surgery (patient preference) would experience improved quality of life.\n\nRetrospective analysis of our patient database (1998-2003, n=313) identified 60 patients who underwent laparoscopic antireflux surgery for the indication of patient preference. Two generic quality-of-life questionnaires (Short Form 36 and Psychological General Well-Being index) and a gastrointestinal symptom questionnaire (Gastrointestinal Symptom Rating Scale) were completed preoperatively, while on medical therapy, and 6 months after surgery.\n\nThirty-eight patients completed all three questionnaires at both time intervals: 31 males, seven females; mean age 42 (15-66) years. Preoperative scores while on medical therapy were significantly improved after surgery: Short Form 36 median physical composite scores 52.0 and 54.0 (P=0.034) and mental composite scores 51.0 and 56.0 (P=0.020); Psychological General Well-Being median total scores 78.0 and 90.0 (P=0.0001); Gastrointestinal Symptom Rating Scale median total scores 2.13 and 1.73 (P=0.0007) and reflux scores 2.50 and 1.00 (P<0.0001).", "target": "yes", "year": "2008", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "27338535", "question": "Do risk calculators accurately predict surgical site occurrences?", "context": "Current risk assessment models for surgical site occurrence (SSO) and surgical site infection (SSI) after open ventral hernia repair (VHR) have limited external validation. Our aim was to determine (1) whether existing models stratify patients into groups by risk and (2) which model best predicts the rate of SSO and SSI.\n\nPatients who underwent open VHR and were followed for at least 1 mo were included. Using two data sets-a retrospective multicenter database (Ventral Hernia Outcomes Collaborative) and a single-center prospective database (Prospective)-each patient was assigned a predicted risk with each of the following models: Ventral Hernia Risk Score (VHRS), Ventral Hernia Working Group (VHWG), Centers for Disease Control and Prevention Wound Class, and Hernia Wound Risk Assessment Tool (HW-RAT). Patients in the Prospective database were also assigned a predicted risk from the American College of Surgeons National Surgical Quality Improvement Program (ACS-NSQIP). Areas under the receiver operating characteristic curve (area under the curve [AUC]) were compared to assess the predictive accuracy of the models for SSO and SSI. Pearson's chi-square was used to determine which models were able to risk-stratify patients into groups with significantly differing rates of actual SSO and SSI.\n\nThe Ventral Hernia Outcomes Collaborative database (n = 795) had an overall SSO and SSI rate of 23% and 17%, respectively. The AUCs were low for SSO (0.56, 0.54, 0.52, and 0.60) and SSI (0.55, 0.53, 0.50, and 0.58). The VHRS (P = 0.01) and HW-RAT (P < 0.01) significantly stratified patients into tiers for SSO, whereas the VHWG (P < 0.05) and HW-RAT (P < 0.05) stratified for SSI. In the Prospective database (n = 88), 14% and 8% developed an SSO and SSI, respectively. The AUCs were low for SSO (0.63, 0.54, 0.50, 0.57, and 0.69) and modest for SSI (0.81, 0.64, 0.55, 0.62, and 0.73). The ACS-NSQIP (P < 0.01) stratified for SSO, whereas the VHRS (P < 0.01) and ACS-NSQIP (P < 0.05) stratified for SSI. In both databases, VHRS, VHWG, and Centers for Disease Control and Prevention overestimated risk of SSO and SSI, whereas HW-RAT and ACS-NSQIP underestimated risk for all groups.", "target": "no", "year": "2016", "labels": ["INTRODUCTION", "METHODS", "RESULTS"]}
{"id": "23359100", "question": "Is etoricoxib effective in preventing heterotopic ossification after primary total hip arthroplasty?", "context": "Heterotopic ossification is a common complication after total hip arthroplasty. Non-steroidal anti-inflammatory drugs (NSAIDs) are known to prevent heterotopic ossifications effectively, however gastrointestinal complaints are reported frequently. In this study, we investigated whether etoricoxib, a selective cyclo-oxygenase-2 (COX-2) inhibitor that produces fewer gastrointestinal side effects, is an effective alternative for the prevention of heterotopic ossification.\n\nWe investigated the effectiveness of oral etoricoxib 90 mg for seven days in a prospective two-stage study design for phase-2 clinical trials in a small sample of patients (n = 42). A cemented primary total hip arthroplasty was implanted for osteoarthritis. Six months after surgery, heterotopic ossification was determined on anteroposterior pelvic radiographs using the Brooker classification.\n\nNo heterotopic ossification was found in 62 % of the patients that took etoricoxib; 31 % of the patients had Brooker grade 1 and 7 % Brooker grade 2 ossification.", "target": "yes", "year": "2013", "labels": ["PURPOSE", "METHODS", "RESULTS"]}
{"id": "26085176", "question": "MR Diagnosis of Bone Metastases at 1.5 T and 3 T: Can STIR Imaging Be Omitted?", "context": "To date, no prospective comparative study of the diagnostic value of STIR versus T1-weighted (T1w) sequences at both 1.5 T and 3 T has been performed with special focus on the detectability of bone metastases.\n\n212 oncological patients had a whole-body MRI at 1.5 T and/or at 3 T. The standard protocol comprised STIR and T1w sequences. All patients who showed typical signs of bone metastases were included in the study. Evaluation of the images was performed by the calculation of the number of metastases by three independent readers and by visual assessment on a 4-point scale.\n\n86 patients fulfilled the inclusion criteria. The total number of metastases was significantly higher on T1w than on STIR images at both field strengths (p<0.05). T1w revealed a sensitivity of 99.72% (3 T) and 100.00% (1.5 T) versus STIR with 70.99 % (3 T) and 79.34 % (1.5 T). In 53% (38/72) of all patients, STIR detected fewer bone metastases in comparison with T1w at 3 T. At 1.5 T, STIR showed inferior results in 37.5 % (18/48) of all patients. Qualitative analysis indicated a significantly better lesion conspicuity, lesion delineation and an improved image quality on T1w compared to STIR imaging at both field strengths (p<0.05) with similar results for T1w at 1.5 T and 3 T, but inferior results for STIR especially at 3 T.", "target": "yes", "year": "2015", "labels": ["OBJECTIVE", "MATERIALS AND METHODS", "RESULTS"]}
{"id": "9602458", "question": "Does the Child Health Computing System adequately identify children with cerebral palsy?", "context": "This paper assesses the usefulness of the Child Health Computing System as a source of information about children with cerebral palsy.\n\nA comparative survey of information held on the Child Health Computing System (CHCS) and the Northern Ireland Cerebral Palsy Register (NICPR) in one Health and Social Services Board in Northern Ireland was carried out. The sample comprised children with cerebral palsy aged 5-9 years.\n\nOf the 135 cases recorded on the NICPR, 47 per cent were not found on the CHCS; the majority of these children had no computer record of any medical diagnosis. Of the 82 cases recorded on the CHCS, 10 (12 per cent) were not found on the NICPR; five of these cases (6 per cent) were found on follow-up not to have CP.", "target": "no", "year": "1998", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "20304513", "question": "Is (18)F-FDG a surrogate tracer to measure tumor hypoxia?", "context": "Fluorodeoxyglucose (FDG) has been reported as a surrogate tracer to measure tumor hypoxia with positron emission tomography (PET). The hypothesis is that there is an increased uptake of FDG under hypoxic conditions secondary to enhanced glycolysis, compensating the hypoxia-induced loss of cellular energy production. Several studies have already addressed this issue, some with conflicting results. This study aimed to compare the tracers (14)C-EF3 and (18)F-FDG to detect hypoxia in mouse tumor models.\n\nC3H, tumor-bearing mice (FSAII and SCCVII tumors) were injected iv with (14)C-EF3, and 1h later with (18)F-FDG. Using a specifically designed immobilization device with fiducial markers, PET (Mosaic®, Philips) images were acquired 1h after the FDG injection. After imaging, the device containing mouse was frozen, transversally sliced and imaged with autoradiography (AR) (FLA-5100, Fujifilm) to obtain high resolution images of the (18)F-FDG distribution within the tumor area. After a 48-h delay allowing for (18)F decay a second AR was performed to image (14)C-EF3 distribution. AR images were aligned to reconstruct the full 3D tumor volume, and were compared with the PET images. Image segmentation with threshold-based methods was applied on both AR and PET images to derive various tracer activity volumes. The matching index DSI (dice similarity index) was then computed. The comparison was performed under normoxic (ambient air\n\nn=4, SCCVII, n=5) and under hypoxic conditions (10% O(2) breathing\n\nn=4).\n\nOn AR, under both ambient air and hypoxic conditions, there was a decreasing similarity between (14)C-EF3 and FDG with higher activity sub-volumes. Under normoxic conditions, when comparing the 10% of tumor voxels with the highest (18)F-FDG or (14)C-EF3 activity, a DSI of 0.24 and 0.20 was found for FSAII and SCCVII, respectively. Under hypoxic conditions, a DSI of 0.36 was observed for SCCVII tumors. When comparing the (14)C-EF3 distribution in AR with the corresponding (18)F-FDG-PET images, the DSI reached values of 0.26, 0.22 and 0.21 for FSAII and SCCVII under normoxia and SCCVII under hypoxia, respectively.", "target": "no", "year": "2010", "labels": ["INTRODUCTION", "MATERIALS AND METHODS", ", FSAII", ", SCCVII", "RESULTS"]}
{"id": "20401819", "question": "Is ultrasound equal to X-ray in pediatric fracture diagnosis?", "context": "Ultrasound is currently not established for the diagnosis of fractures. The aim of this study was to compare ultrasound and X-ray beyond their use solely for the identification of fractures, i. e., for the detection of fracture type and dislocation for pediatric fracture diagnosis.\n\nLimb bones of dead young pigs served as a model for pediatric bones. The fractured bones were examined with ultrasound, X-ray, and CT, which served as the gold standard.\n\n162 of 248 bones were fractured. 130 fractures were identified using ultrasound, and 148 using X-ray. There were some advantages of X-ray over ultrasound in the detection of fracture type (80 correct results using X-ray, 66 correct results using ultrasound). Ultrasound, however, was superior to X-ray for dislocation identification (41 correct results using X-ray, 51 correct results using ultrasound). Both findings were not statistically significant after adjustment for multiple testing.", "target": "yes", "year": "2010", "labels": ["PURPOSE", "MATERIALS AND METHODS", "RESULTS"]}
{"id": "15687156", "question": "Can normal knee kinematics be restored with unicompartmental knee replacement?", "context": "Unicompartmental replacement can be an alternative to tibial osteotomy in younger, active patients with unicompartmental knee disease. In unicompartmental replacement, the other compartments and knee ligaments are largely untouched. Therefore, it was hypothesized that the knee kinematics after unicompartmental replacement may also be unchanged. To test this hypothesis, knee kinematics and quadriceps tension were recorded before and after replacement with a unicompartmental design and then with a tricompartmental design.\n\nSix human cadaver knees were tested before implantation, after implantation with a bicruciate-retaining unicompartmental knee prosthesis, and after implantation with a posterior cruciate-retaining tricompartmental knee prosthesis. The unicompartmental prosthesis was initially implanted, and it was then revised to a total condylar knee replacement. The knee kinematics were measured with use of an electromagnetic tracking device while the knee was put through dynamic simulated stair-climbing under peak flexion moments of approximately 40 N-m. Quadriceps tension was also measured for all three conditions.\n\nNo significant differences in tibial axial rotation were noted between the intact and unicompartmental conditions. However, tricompartmental replacement significantly affected tibial axial rotation (p = 0.001). Femoral rollback was not significantly affected by either unicompartmental or tricompartmental arthroplasty. Quadriceps tension was also similar among all three conditions.", "target": "no", "year": "2005", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "23414523", "question": "Does binge drinking during early pregnancy increase the risk of psychomotor deficits?", "context": "The potential effects of binge drinking during pregnancy on child motor function have only been assessed in a few, small studies. We aimed to examine the effects of binge alcohol consumption during early pregnancy, including number of binge episodes and timing of binge drinking, on child motor function at age 5.\n\nWe performed a prospective follow-up study of 678 women and their children sampled from the Danish National Birth Cohort based on maternal alcohol consumption during pregnancy. At 5 years of age, the children were tested with the Movement Assessment Battery for Children. Parental education, maternal IQ, prenatal maternal smoking, the child's age at testing, sex of child, and tester were considered core confounders, while the full model also controlled for prenatal maternal average alcohol intake, maternal age and prepregnancy body mass index, parity, home environment, postnatal parental smoking, health status, participation in organized sport, and indicators for hearing and vision impairment.\n\nThere were no systematic or significant differences in motor function between children of mothers reporting isolated episodes of binge drinking and children of mothers with no binge episodes. No association was observed with respect to the number of binge episodes (maximum of 12) and timing of binge drinking.", "target": "no", "year": "2013", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "27044366", "question": "Detailed analysis of sputum and systemic inflammation in asthma phenotypes: are paucigranulocytic asthmatics really non-inflammatory?", "context": "The technique of induced sputum has allowed to subdivide asthma patients into inflammatory phenotypes according to their level of granulocyte airway infiltration. There are very few studies which looked at detailed sputum and blood cell counts in a large cohort of asthmatics divided into inflammatory phenotypes. The purpose of this study was to analyze sputum cell counts, blood leukocytes and systemic inflammatory markers in these phenotypes, and investigate how those groups compared with healthy subjects.\n\nWe conducted a retrospective cross-sectional study on 833 asthmatics recruited from the University Asthma Clinic of Liege and compared them with 194 healthy subjects. Asthmatics were classified into inflammatory phenotypes.\n\nThe total non-squamous cell count per gram of sputum was greater in mixed granulocytic and neutrophilic phenotypes as compared to eosinophilic, paucigranulocytic asthma and healthy subjects (p < 0.005). Sputum eosinophils (in absolute values and percentages) were increased in all asthma phenotypes including paucigranulocytic asthma, compared to healthy subjects (p < 0.005). Eosinophilic asthma showed higher absolute sputum neutrophil and lymphocyte counts than healthy subjects (p < 0.005), while neutrophilic asthmatics had a particularly low number of sputum macrophages and epithelial cells. All asthma phenotypes showed an increased blood leukocyte count compared to healthy subjects (p < 0.005), with paucigranulocytic asthmatics having also increased absolute blood eosinophils compared to healthy subjects (p < 0.005). Neutrophilic asthma had raised CRP and fibrinogen while eosinophilic asthma only showed raised fibrinogen compared to healthy subjects (p < 0.005).", "target": "maybe", "year": "2016", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "12612531", "question": "Fragility of the esophageal mucosa: a pathognomonic endoscopic sign of primary eosinophilic esophagitis?", "context": "Primary eosinophilic esophagitis, a chronic inflammatory disorder of the esophagus, evokes recurrent dysphagia. Endoscopy is often unremarkable, and no consensus exists regarding management of resultant dysphagia. The response of a series of patients with primary eosinophilic esophagitis to dilation is reported together with a description of a possibly pathognomonic sign: fragile esophageal mucosa, for which the term \"crêpe-paper\" mucosa is introduced.\n\nFive men underwent endoscopy because of dysphagia confirmed (clinically, endoscopically, and histologically) to be caused by primary eosinophilic esophagitis and were treated by bouginage.\n\nAll patients had extremely fragile, inelastic, and delicate mucosa, which tore easily even with minor trauma. After the procedure, patients remained asymptomatic for 3 to 24 months.", "target": "yes", "year": "2003", "labels": ["BACKGROUND", "METHODS", "OBSERVATIONS"]}
{"id": "23283159", "question": "Is obesity a risk factor for wheezing among adolescents?", "context": "To investigate the effect of obesity at the start of adolescence on the prevalence, incidence and maintenance of chest wheezing among individuals aged 11-15 years in a birth cohort in a developing country.\n\nThe seventh follow-up of the 1993 Pelotas birth cohort occurred in 2004 (individuals aged 10-11 years). Between January and August 2008, the eighth follow-up of the cohort was conducted. All the individuals of the original cohort who were alive (who were then adolescents aged between 14 and 15 years) were targets for the study. The International Study of Asthma and Allergies in Childhood (ISAAC) questionnaire was used to define wheezing. In addition to the body mass index (BMI), used to define obesity by the World Health Organization (WHO) criteria, we assessed skinfold thickness.\n\nFrom the original cohort, 4,349 individuals were located (85.7% follow-up rate). The prevalence of chest wheezing at 11 and 15 years were 13.5% (95% CI: 12.5%-14.5%) and 12.1% (95% CI: 11.1%-13.1%), respectively. The prevalence of wheezing at both times was 4.5% (95% CI: 3.9%-5.1%) and the incidence of wheezing was 7.5% (95% CI: 6.7%-8.3%). Independent of the effect of various confounding variables, the prevalence of wheezing at 15 years was 50% greater among obese individuals than among eutrophic individuals at 11 years (RR 1.53; 95% CI: 1.14-2.05). The greater the skinfold tertile at 11 years, the higher the prevalence of wheezing at 15 years was (p = .011). Weight status and skinfolds did not present any association with incident wheezing. After controlling for confounding factors, the risk of persistent wheezing among obese individuals at 11 years was 1.82 (95% CI: 1.30-2.54).", "target": "yes", "year": "2012", "labels": ["PURPOSE", "METHODS", "RESULTS"]}
{"id": "26516021", "question": "Does evidence-based practice improve patient outcomes?", "context": "Evidence-based practice (EBP) is widely promoted, but does EBP produce better patient outcomes? We report a natural experiment when part of the internal medicine service in a hospital was reorganized in 2003 to form an EBP unit, the rest of the service remaining unchanged. The units attended similar patients until 2012 permitting comparisons of outcomes and activity.\n\nWe used routinely collected statistics (2004-11) to compare the two different methods of practice and test whether patients being seen by the EBP unit differed from standard practice (SP) patients. Data were available by doctor and year. To check for differences between the EBP and SP doctors prior to reorganization, we used statistics from 2000 to 2003. We looked for changes in patient outcomes or activity following reorganization and whether the EBP unit was achieving significantly different results from SP. Data across the periods were combined and tested using Mann-Whitney test.\n\nNo statistically significant differences in outcomes were detected between the EBP and the SP doctors prior to reorganization. Following the unit's establishment, the mortality of patients being treated by EBP doctors compared with their previous performance dropped from 7.4% to 6.3% (P < 0.02) and length of stay from 9.15 to 6.01 days (P = 0.002). No statistically significant improvements were seen in SP physicians' performance. No differences in the proportion of patients admitted or their complexity between the services were detected. Despite this, EBP patients had a clinically significantly lower risk of death 6.27% versus 7.75% (P < 0.001) and a shorter length of stay 6.01 versus 8.46 days (P < 0.001) than SP patients. Readmission rates were similar: 14.4% (EBP); 14.5% (SP). EBP doctors attended twice as many patients/doctor as SP doctors.", "target": "yes", "year": "2015", "labels": ["RATIONALE, AIMS AND OBJECTIVES", "METHODS", "RESULTS"]}
{"id": "11413427", "question": "Does transverse apex coincide with coronal apex levels (regional or global) in adolescent idiopathic scoliosis?", "context": "Cross-sectional.\n\nTo identify the regional and global apexes of curves in adolescent idiopathic scoliosis and to compare the levels of those with the most rotated vertebral levels on computed tomography scans.\n\nThe terminology regarding the terms and definitions had been arbitrary until being refined and standardized by the Scoliosis Research Society Working Group on Three-Dimensional Terminology of Spinal Deformity. Apical vertebra or disc is defined as the most laterally deviated vertebra or disc in a scoliosis curve, but the most rotated vertebra (or disc) has not been included in this terminology. One study suggested that the most rotated vertebral level was always located at the apex.\n\nThirty-three structural curves of 25 consecutive patients scheduled for surgery for thoracic or thoracolumbar scoliosis were analyzed with standing anteroposterior radiographs and computed tomography scans covering the curve apexes and pelvis. Thoracic and lumbar curves were evaluated separately for all Type II curves. Vertebral rotations were normalized by the rotation of the pelvis. The most rotated vertebral (or disc) levels (transverse apex) were compared with the regional and global apex levels (vertebra or disc) (coronal apexes) of the corresponding curves separately.\n\nRegional and global apexes were at the same level in 18 (54.5%) curves, and within half a level in another 15 (45.4%), and the regional apex was one level higher in two curves (95% confidence levels: -0.82, +0.88). Comparison of the most rotated levels with regional and global apex levels revealed a higher variability, extending up to two levels for the global apex (95% confidence levels: -1.19, +1.54 levels for the global and -1.0, +1.41 levels for the regional apexes).", "target": "no", "year": "2001", "labels": ["STUDY DESIGN", "OBJECTIVES", "SUMMARY OF BACKGROUND DATA", "METHODS", "RESULTS"]}
{"id": "9381529", "question": "Immune suppression by lysosomotropic amines and cyclosporine on T-cell responses to minor and major histocompatibility antigens: does synergy exist?", "context": "Using murine models, we have shown that the lysosomotropic amine, chloroquine, is effective in the prevention of graft-versus-host disease (GVHD) mediated by donor T cells reactive with recipient minor histocompatibility antigens (MiHCs). Because lysosomotropic amines can suppress major histocompatibility complex (MHC) class II antigen presentation, their mechanism of action is potentially different from current immune suppressant drugs used to control GVHD such as cyclosporine.\n\nWe investigated the use of cyclosporine and the lysosomotropic amines chloroquine and hydroxychloroquine in combination for additive or synergistic immunosuppression on T-cell responses in vitro to MiHC and MHC in mice.\n\nWe found that similar concentrations of chloroquine and hydroxychloroquine suppress the T-cell response to MiHC in mice (C57BL/6 anti-BALB.B) and that lysosomotropic amines in combination with cyclosporine result in synergistic suppression of a proliferative response to MiHC. Similar suppression and synergy appear to be present in an alloreactive response (C57BL/6 anti-BALB/c). Direct inhibition by chloroquine of T-cell proliferative responses induced by anti-CD3epsilon in the absence of antigen-presenting cells is present at higher concentrations than that required to suppress responses to MiHC or MHC. Chloroquine appears to induce decreased T-cell viability at high concentrations. This effect does not appear to be due to decreased T-cell production of interleukin-2 or interferon-gamma. At lower concentrations (<25 microg/ml), chloroquine can also decrease the ability of antigen-presenting cells to stimulate an a C57BL/6 anti-BALB/c T-cell response and can inhibit MHC class II expression after activation with lipopolysaccharide.", "target": "yes", "year": "1997", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "18568290", "question": "Is there a role for endothelin-1 in the hemodynamic changes during hemodialysis?", "context": "The etiology of hemodialysis (HD)-induced hypotension and hypertension remains speculative. There is mounting evidence that endothelin-1 (ET-1) may play a vital role in these hemodynamic changes. We examined the possible role of intradialytic changes of ET-1 in the pathogenesis of hypotension and rebound hypertension during HD.\n\nThe present study included 45 patients with end-stage renal disease (ESRD) on regular HD. They were divided according to their hemodynamic status during HD into three groups (group I had stable intradialytic hemodynamics, group II had dialysis-induced hypotension, and group III had rebound hypertension during HD). In addition, 15 healthy volunteers were included as a control group. Pulse and blood pressure were monitored before, during (every half hour), and after HD session. ET-1 level was measured at the beginning, middle, and end of HD. ET-1 was measured in the control group for comparison.\n\nPre-dialysis levels of ET-1 were significantly higher in dialysis patients compared to the controls (P<0.001); however, they were comparable in the three HD groups. The post-dialysis ET-1 level was not changed significantly in group I compared with predialysis values (14.49 +/- 2.04 vs. 14.33 +/- 2.23 pg/ml; P = NS), while the ET-1 concentration decreased significantly in group II and increased in group III in comparison to predialysis values (8.56 +/- 1.44 vs. 11.75 +/- 2.51; 16.39 +/- 3.12 vs. 11.93 +/- 2.11 pg/ml, respectively; P<0.001).", "target": "maybe", "year": "2008", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "24267613", "question": "Is the advanced age a contraindication to GERD laparoscopic surgery?", "context": "In this prospective non randomized observational cohort study we have evaluated the influence of age on outcome of laparoscopic total fundoplication for GERD.\n\nSix hundred and twenty consecutive patients underwent total laparoscopic fundoplication for GERD. Five hundred and twenty-four patients were younger than 65 years (YG), and 96 patients were 65 years or older (EG). The following parameters were considered in the preoperative and postoperative evaluation: presence, duration, and severity of GERD symptoms, presence of a hiatal hernia, manometric and 24 hour pH-monitoring data, duration of operation, incidence of complications and length of hospital stay.\n\nElderly patients more often had atypical symptoms of GERD and at manometric evaluation had a higher rate of impaired esophageal peristalsis in comparison with younger patients. The duration of the operation was similar between the two groups. The incidence of intraoperative and postoperative complications was low and the difference was not statistically significant between the two groups. An excellent outcome was observed in 93.0% of young patients and in 88.9% of elderly patients (p = NS).", "target": "no", "year": "2013", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "17259061", "question": "Cigarettes and cinema: does parental restriction of R-rated movie viewing reduce adolescent smoking susceptibility?", "context": "To examine the relationship between exposure to pro-smoking messages in media and susceptibility to smoking adoption among middle school students. The hypothesis that parental restriction of R-rated movie viewing is associated with lower adolescent smoking susceptibility was tested.\n\nA sample of 1687 6th-, 7th-, and 8th-grade students from four Wisconsin middle schools were surveyed about their use of cigarettes, exposure to smoking in media, their views of smoking, and peer smoking behaviors.\n\nAn index of smoking susceptibility was created using measures of cigarette use and future intention to smoke. A zero-order correlation for parental restriction of R-rated movie viewing and smoking susceptibility showed a strong association (r = -.36, p<.001). A hierarchical logistic regression yielded odds ratios (ORs) for being susceptible to or having tried smoking for three levels of parental R-rated movie restriction. Results show that compared to full restriction, respondents with partial or no restriction were more likely to be susceptible to smoking (partial restriction: OR = 2.1, 95% CI = 1.5-2.8; no restriction: OR = 3.3, 95% CI = 2.3-4.6), when controlling for demographic factors, and family and friend smoking. Analyses using a measure of smoking prevalence as the dependent variable yielded similar results (partial restriction: OR = 1.5, 95% CI = 1.0-2.2; no restriction: OR = 2.5, 95% CI = 1.7-3.7).", "target": "yes", "year": "2007", "labels": ["PURPOSE", "METHODS", "RESULTS"]}
{"id": "19322056", "question": "Does the enteral feeding advancement affect short-term outcomes in very low birth weight infants?", "context": "Controversy exists regarding the optimal enteral feeding regimen of very low birth weight infants (VLBW). Rapid advancement of enteral feeding has been associated with an increased rate of necrotizing enterocolitis. In contrast, delaying enteral feeding may have unfavorable effects on nutrition, growth, and neurodevelopment. The aim is to compare the short-term outcomes of VLBW infants in tertiary care centers according to their enteral feeding advancement.\n\nWe prospectively studied the influence of center-specific enteral feeding advancement in 1430 VLBW infants recruited from 13 tertiary neonatal intensive care units in Germany on short-term outcome parameters. The centers were post hoc stratified to \"rapid advancement to full enteral feeds\" (median duration of advancement to full enteral feeds<or =12.5 days; 6 centers), that is, rapid advancement (RA), or \"slow advancement to full enteral feeds\" (median duration of advancement to full enteral feeds>12.5 days; 7 centers), that is, slow advancement (SA).\n\nVLBW infants born in centers with SA (n = 713) had a significantly higher rate of sepsis compared with VLBW infants born in centers with RA (n = 717), which was particularly evident for late-onset sepsis (14.0% vs 20.4%; P = 0.002). Furthermore, more central venous lines (48.6% vs 31.1%, P<0.001) and antibiotics (92.4% vs 77.7%, P<0.001) were used in centers with SA.", "target": "yes", "year": "2009", "labels": ["BACKGROUND AND OBJECTIVES", "PATIENTS AND METHODS", "RESULTS"]}
{"id": "20530150", "question": "Is cholecystectomy really an indication for concomitant splenectomy in mild hereditary spherocytosis?", "context": "Children referred with symptomatic gallstones complicating HS between April 1999 and April 2009 were prospectively identified and reviewed retrospectively. During this period, the policy was to undertake concomitant splenectomy only if indicated for haematological reasons and not simply because of planned cholecystectomy.\n\nA total of 16 patients (mean age 10.4, range 3.7 to 16 years, 11 women) with HS and symptomatic gallstones underwent cholecystectomy. Three patients subsequently required a splenectomy for haematological reasons 0.8-2.5 years after cholecystectomy; all three splenectomies were performed laparoscopically. There were no postoperative complications in the 16 patients; postoperative hospital stay was 1-3 days after either cholecystectomy or splenectomy. The 13 children with a retained spleen remain under regular review by a haematologist (median follow-up 4.6, range 0.5 to 10.6 years) and are well and transfusion independent.", "target": "no", "year": "2010", "labels": ["METHODS", "RESULTS"]}
{"id": "22440363", "question": "Mitral replacement or repair for functional mitral regurgitation in dilated and ischemic cardiomyopathy: is it really the same?", "context": "This was a study to compare the results of mitral valve (MV) repair and MV replacement for the treatment of functional mitral regurgitation (MR) in advanced dilated and ischemic cardiomyopathy (DCM).\n\nOne-hundred and thirty-two patients with severe functional MR and systolic dysfunction (mean ejection fraction 0.32 ± 0.078) underwent mitral surgery in the same time frame. The decision to replace rather than repair the MV was taken when 1 or more echocardiographic predictors of repair failure were identified at the preoperative echocardiogram. Eighty-five patients (64.4%) received MV repair and 47 patients (35.6%) received MV replacement. Preoperative characteristics were comparable between the 2 groups. Only ejection fraction was significantly lower in the MV repair group (0.308 ± 0.077 vs 0.336 ± 0.076, p = 0.04).\n\nHospital mortality was 2.3% for MV repair and 12.5% for MV replacement (p = 0.03). Actuarial survival at 2.5 years was 92 ± 3.2% for MV repair and 73 ± 7.9% for MV replacement (p = 0.02). At a mean follow-up of 2.3 years (median, 1.6 years), in the MV repair group LVEF significantly increased (from 0.308 ± 0.077 to 0.382 ± 0.095, p<0.0001) and LV dimensions significantly decreased (p = 0.0001). On the other hand, in the MV replacement group LVEF did not significantly change (from 0.336 ± 0.076 to 0.31 ± 0.11, p = 0.56) and the reduction of LV dimensions was not significant. Mitral valve replacement was identified as the only predictor of hospital (odds ratio, 6; 95% confidence interval, 1.1 to 31; p = 0.03) and overall mortality (hazard ratio, 3.1; 95% confidence interval, 1.1 to 8.9; p = 0.02).", "target": "no", "year": "2012", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "19444061", "question": "Does ossification of the posterior longitudinal ligament affect the neurological outcome after traumatic cervical cord injury?", "context": "Retrospective outcome measurement study.\n\nThe purpose of this study is to assess whether ossification of the posterior longitudinal ligament (OPLL) affects neurologic outcomes in patients with acute cervical spinal cord injury (SCI).\n\nThere have so far been few reports examining the relationship between OPLL and SCI and there is controversy regarding the deteriorating effects of OPLL-induced canal stenosis on neurologic outcomes.\n\nTo obtain a relatively uniform background, patients nonsurgically treated for an acute C3-C4 level SCI without any fractures or dislocations of the spinal column were selected, resulting in 129 patients. There were 110 men and 19 women (mean age was 61.1 years), having various neurologic conditions on admission (American Spinal Injury Association [ASIA] impairment scale A, 43; B, 16; C, 58; D, 12). The follow-up period was the duration of their hospital stay and ranged from 50 to 603 days (mean, 233 days). The presence of OPLL, the cause of injury, the degree of canal stenosis (both static and dynamic), and the neurologic outcomes in motor function, including improvement rate, were assessed.\n\nOf the 129 patients investigated in this study, OPLL was identified at the site of the injury in 13 patients (10.1%). In this OPLL+ group, the static and dynamic canal diameters at C3 and C4 were significantly smaller than those of the remaining 116 patients (OPLL- group). However, no significant difference was observed between the 2 groups in terms of ASIA motor score both at the time of administration and discharge, and the mean improvement rate in ASIA motor score was 55.5 +/- 9.0% in OPLL+ group, while it was 43.1 +/- 2.8% in the OPLL-group. Furthermore, no significant correlation was observed between the static/dynamic canal diameters and neurologic outcome in all 129 patients.", "target": "no", "year": "2009", "labels": ["STUDY DESIGN", "OBJECTIVES", "SUMMARY OF BACKGROUND DATA", "METHODS", "RESULTS"]}
{"id": "17276801", "question": "Can elevated troponin I levels predict complicated clinical course and inhospital mortality in patients with acute pulmonary embolism?", "context": "The purpose of this study was to evaluate the value of elevated cardiac troponin I (cTnI) for prediction of complicated clinical course and in-hospital mortality in patients with confirmed acute pulmonary embolism (PE).\n\nThis study was a retrospective chart review of patients diagnosed as having PE, in whom cTnI testing was obtained at emergency department (ED) presentation between January 2002 and April 2006. Clinical characteristics; echocardiographic right ventricular dysfunction; inhospital mortality; and adverse clinical events including need for inotropic support, mechanical ventilation, and thrombolysis were compared in patients with elevated cTnI levels vs patients with normal cTnI levels. One hundred sixteen patients with PE were identified, and 77 of them (66%) were included in the study. Thirty-three patients (42%) had elevated cTnI levels. Elevated cTnI levels were associated with inhospital mortality (P = .02), complicated clinical course (P<.001), and right ventricular dysfunction (P<.001). In patients with elevated cTnI levels, inhospital mortality (odds ratio [OR], 3.31; 95% confidence interval [CI], 1.82-9.29), hypotension (OR, 7.37; 95% CI, 2.31-23.28), thrombolysis (OR, 5.71; 95% CI, 1.63-19.92), need for mechanical ventilation (OR, 5.00; 95% CI, 1.42-17.57), and need for inotropic support (OR, 3.02; 95% CI, 1.03-8.85) were more prevalent. The patients with elevated cTnI levels had more serious vital parameters (systolic blood pressure, pulse, and oxygen saturation) at ED presentation.", "target": "yes", "year": "2007", "labels": ["OBJECTIVE", "METHODS AND RESULTS"]}
{"id": "19757704", "question": "Is Chaalia/Pan Masala harmful for health?", "context": "To determine the practices and knowledge of harmful effects regarding use of Chaalia and Pan Masala in three schools of Mahmoodabad and Chanesar Goth, Jamshed Town, Karachi, Pakistan.\n\nTo achieve the objective a cross-sectional design was used in three government schools of Mahmoodabad and Chanesar Goth, Jamshed Town, Karachi. Students of either gender drawn from these schools fulfilling the inclusion and exclusion criteria were interviewed using a pre-coded structured questionnaire. Along with demographic data, questions regarding frequency of Chaalia and Pan Masala use, practices of this habit in friends and family and place of procurement of these substances, were inquired. Knowledge was assessed about harmful effects and its source of information. In addition, practices in relation to that knowledge were assessed.\n\nA total of 370 students were interviewed over a period of six weeks, of which 205 (55.4%) were boys. The ages of the students were between 10 and 15 years. Thirty one percent of the fathers and 62% of the mothers were uneducated. The frequency of use of any brand of Chaalia was found to be 94% and that of Pan Masala was 73.8%. Eighty five percent of them were regular users. A large majority (88%) procured the substances themselves from near their homes. Ninety five percent of the children had friends with the same habits. Eighty four percent were using the substances in full knowledge of their families. Chaalia was considered harmful for health by 96% and Pan Masala by 60%. Good taste was cited as a reason for continuing the habit by 88.5% of the children and use by friends by 57%. Knowledge about established harmful effects was variable. Knowledge about harmful effects was high in both \"daily\" and \"less than daily users\".", "target": "yes", "year": "2009", "labels": ["OBJECTIVE", "METHODS", "RESULTS"]}
{"id": "18928979", "question": "Can myometrial electrical activity identify patients in preterm labor?", "context": "The objective of the study was to determine whether myometrial electrical activity can differentiate false from true preterm labor.\n\nElectrical uterine myography (EUM) was measured prospectively on 87 women, gestational age less than 35 weeks. The period between contractions, power of contraction peaks and movement of center of electrical activity (RMS), was used to develop an index score (1-5) for prediction of preterm delivery (PTD) within 14 days of the test. The score was compared with fetal fibronectin (fFN) and cervical length (CL).\n\nPatients delivering within 14 days from testing showed a higher index and mean RMS (P = .000). No patients with EUM index scores of 1-2 delivered in this time frame. Combining EUM with CL or fFN increased predictability. Logistic regression revealed that history of PTD and EUM index had 4- to 5-fold increased risk for PTD. Gestational age at testing, body mass index, fFN, and CL were nonsignificant contributors to PTD risk.", "target": "yes", "year": "2008", "labels": ["OBJECTIVE", "STUDY DESIGN", "RESULTS"]}
{"id": "24433626", "question": "Prevalence of chronic conditions among Medicare Part A beneficiaries in 2008 and 2010: are Medicare beneficiaries getting sicker?", "context": "Medicare beneficiaries who have chronic conditions are responsible for a disproportionate share of Medicare fee-for-service expenditures. The objective of this study was to analyze the change in the health of Medicare beneficiaries enrolled in Part A (hospital insurance) between 2008 and 2010 by comparing the prevalence of 11 chronic conditions.\n\nWe conducted descriptive analyses using the 2008 and 2010 Chronic Conditions Public Use Files, which are newly available from the Centers for Medicare and Medicaid Services and have administrative (claims) data on 100% of the Medicare fee-for-service population. We examined the data by age, sex, and dual eligibility (eligibility for both Medicare and Medicaid).\n\nMedicare Part A beneficiaries had more chronic conditions on average in 2010 than in 2008. The percentage increase in the average number of chronic conditions was larger for dual-eligible beneficiaries (2.8%) than for nondual-eligible beneficiaries (1.2%). The prevalence of some chronic conditions, such as congestive heart failure, ischemic heart disease, and stroke/transient ischemic attack, decreased. The deterioration of average health was due to other chronic conditions: chronic kidney disease, depression, diabetes, osteoporosis, rheumatoid arthritis/osteoarthritis. Trends in Alzheimer's disease, cancer, and chronic obstructive pulmonary disease showed differences by sex or dual eligibility or both.", "target": "yes", "year": "2014", "labels": ["INTRODUCTION", "METHODS", "RESULTS"]}
{"id": "10593212", "question": "Does loss of consciousness predict neuropsychological decrements after concussion?", "context": "To investigate the importance of loss of consciousness (LOC) in predicting neuropsychological test performance in a large sample of patients with head injury.\n\nRetrospective comparison of neuropsychological test results for patients who suffered traumatic LOC, no LOC, or uncertain LOC.\n\nAllegheny General Hospital, Pittsburgh, Pennsylvania.\n\nThe total number of patients included in this study was 383.\n\nNeuropsychological test measures, including the visual reproduction, digit span, and logical memory subtests of the Wechsler memory scale (revised), the Trail Making test, Wisconsin Card Sorting test, Hopkins Verbal Learning test, Controlled Oral Word Association, and the Galveston Orientation and Amnesia test (GOAT).\n\nNo significant differences were found between the LOC, no LOC, or uncertain LOC groups for any of the neuropsychological measures used. Patients who had experienced traumatic LOC did not perform more poorly on neuropsychological testing than those with no LOC or uncertain LOC. All three groups demonstrated mildly decreased performance on formal tests of speed of information processing, attentional process, and memory.", "target": "no", "year": "1999", "labels": ["OBJECTIVE", "DESIGN", "SETTING", "PATIENTS", "MAIN OUTCOME MEASURES", "RESULTS"]}
{"id": "21658267", "question": "Do improvements in outreach, clinical, and family and community-based services predict improvements in child survival?", "context": "There are three main service delivery channels: clinical services, outreach, and family and community. To determine which delivery channels are associated with the greatest reductions in under-5 mortality rates (U5MR), we used data from sequential population-based surveys to examine the correlation between changes in coverage of clinical, outreach, and family and community services and in U5MR for 27 high-burden countries.\n\nHousehold survey data were abstracted from serial surveys in 27 countries. Average annual changes (AAC) between the most recent and penultimate survey were calculated for under-five mortality rates and for 22 variables in the domains of clinical, outreach, and family- and community-based services. For all 27 countries and a subset of 19 African countries, we conducted principal component analysis to reduce the variables into a few components in each domain and applied linear regression to assess the correlation between changes in the principal components and changes in under-five mortality rates after controlling for multiple potential confounding factors.\n\nAAC in under 5-mortality varied from 6.6% in Nepal to -0.9% in Kenya, with six of the 19 African countries all experiencing less than a 1% decline in mortality. The strongest correlation with reductions in U5MR was observed for access to clinical services (all countries: p = 0.02, r² = 0.58; 19 African countries p<0.001, r² = 0.67). For outreach activities, AAC U5MR was significantly correlated with antenatal care and family planning services, while AAC in immunization services showed no association. In the family- and community services domain, improvements in breastfeeding were associated with significant changes in mortality in the 30 countries but not in the African subset; while in the African countries, nutritional status improvements were associated with a significant decline in mortality.", "target": "yes", "year": "2011", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "23455575", "question": "Globulomaxillary cysts--do they really exist?", "context": "The so-called \"globulomaxillary cyst\", described as a fissural cyst, caused by entrapped epithelium between the nasal and maxillary process, is no longer considered for its own entity. Nevertheless, cystic lesions, which correspond to the previous image of globulomaxillary cysts, do still occur in daily practice. This raises the question to which entities pathological processes in this particular region actually belong to.\n\nIn a retrospective study, 17 cases (12 men and 5 women, 12-59 years old) of primarily diagnosed globulomaxillary cysts are analysed according to clinical, radiological and histological aspects, catamnestic processed and assigned to a new entity. The results are compared with the international literature and draws conclusions on the diagnostic and therapeutic procedure.\n\nSeven lateral periodontal cysts, four radicular cysts, two keratocystic odontogenic tumours, one adenomatoid odontogenic tumour, one periapical granuloma, one residual cyst and one undefined jaw cyst were determined.", "target": "no", "year": "2014", "labels": ["OBJECTIVES", "MATERIALS AND METHODS", "RESULTS"]}
{"id": "12221908", "question": "The HELPP syndrome--evidence of a possible systemic inflammatory response in pre-eclampsia?", "context": "The principal causes of morbidity and mortality during pregnancy in Mexico, are preeclampsia/eclampsia, obstetric hemorrhage and puerperium complications; this is, 62% of maternal deaths in last years. HELLP syndrome was observed between 5 to 25% of the mortality in pregnancies of 36 weeks or less.\n\nTo analyze patients with HELLP syndrome in ICU's (Intensive Care Unit) of a Gynecology and Obstetric Hospital, related to the abnormal hematological, hepatic and renal results with the obstetric case history and the clinical complications.\n\nA transversal study in patients with HELLP syndrome during 1998 and 1999 were carry out.\n\nPeripheral blood with Microangiopathic hemolysis, elevated liver enzymes: AST, ALT over 40 UI/L, even when were LDH lower than 600 UI/L. It was evaluated the hepatic and renal function, platelets count, microangiopathic hemolysis, arterial pressure, seizures, icteric skin color, blindness, visual disturbances, nausea, vomiting and upper quadrant right abdominal pain. In newborn we analyzed gestational age, sex, weight and APGAR. We studied for an association between maternal and biochemical variables with Correlation Pearson Test, and dependence between variables with lineal regression model.\n\n2878 patients with hypertensives disorders in pregnancy (11.64%). The 1.15% (n = 33) had HELLP syndrome with specific maternal mortality of 0.4 per 10,000 live birth, perinatal mortality of 1.62 per 10,000 live birth; and renal damage in 84.5%. Coefficient beta was higher between number of pregnancies to platelets count (-0.33) and creatinine clearance (-0.401).", "target": "yes", "year": "2002", "labels": ["INTRODUCTION", "OBJECTIVE", "MATERIALS AND METHODS", "CASE DEFINITION", "RESULTS"]}
{"id": "21951591", "question": "Motor performance in chronic low back pain: is there an influence of pain-related cognitions?", "context": "Chronic low back pain (CLBP) is often accompanied by an abnormal motor performance. However, it has not been clarified yet whether these deviations also occur during motor tasks not involving the back and whether the performance is influenced by pain and pain-related cognitions. Therefore, the aim of the present study is to get insight in the contribution of both pain experience and pain-related cognitions to general motor task performance in CLBP.\n\n13 CLBP patients and 15 healthy subjects performed a hand-function task in three conditions: sitting, lying prone (lying) and lying prone without trunk support (provoking). The last condition was assumed to provoke pain-related cognitions, which was considered successful when a patients' pain expectancy on a numeric rating scale was at least 1 point higher than actual pain experienced. Subjects' performance was expressed in reaction time and movement time. Repeated measures analysis of variance was performed to detect main effect for group and condition. Special interest was given to group*condition interaction, since significant interaction would indicate that patients and healthy subjects performed differently throughout the three conditions.\n\nPatients were slower throughout all conditions compared to healthy subjects. With respect to the provoking condition, patients showed deteriorated performance compared to lying while healthy subjects' performance remained equal between these two conditions. Further analysis of patients' data showed that provocation was successful in 54% of the patients. Especially this group showed deteriorated performance in the provoking condition.", "target": "yes", "year": "2011", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "21164063", "question": "Is there a role for fondaparinux in perioperative bridging?", "context": "A possible role for fondaparinux as a bridging agent in the perioperative setting is explored.\n\nAnticoagulation guidelines provide minimal direction on the perioperative use of fondaparinux. Fondaparinux's extended half-life of 17-21 hours complicates its use as a perioperative bridging therapy. The ideal time for discontinuation before surgery is an issue, particularly in surgeries with a high bleeding risk or in which neuraxial anesthesia is used. Guidance for perioperative bridging with fondaparinux must be derived from pharmacokinetic data, surgical prophylaxis trials, case reports, and anesthesia guidelines. Published trials used fondaparinux sodium 2.5 mg daily for venous thromboembolism prophylaxis in surgical patients, and the majority avoided its use before surgery in patients receiving neuraxial anesthesia. Three case reports cited the use of fondaparinux sodium as perioperative bridge therapy; one used a 2.5-mg dose, and the other two used a full treatment dose of 7.5 mg. Furthermore, professional anesthesia guidelines conflict in their recommendations regarding the timing of drug administration with neuraxial catheter use. For these reasons, it may be optimal to avoid fondaparinux use before surgery. In some instances, the use of low-molecular-weight heparin or inpatient use of i.v. unfractionated heparin is not possible, is contraindicated, or has limited efficacy, such as a patient with history of heparin-induced thrombocytopenia or antithrombin III deficiency. Fondaparinux may have a role in bridge therapy for these patients.", "target": "no", "year": "2011", "labels": ["PURPOSE", "SUMMARY"]}
{"id": "20011163", "question": "Can Roux-en-Y gastric bypass provide a lifelong solution for diabetes mellitus?", "context": "The surgical treatment of diabetes had witnessed progressive development and success since the first case of pancreatic transplantation. Although this was a great step, wide clinical application was limited by several factors. Bariatric surgery such as gastric bypass is emerging as a promising option in obese patients with type 2 diabetes. The aim of this article is to explore the current application of gastric bypass in patients with type 2 diabetes and the theoretical bases of gastric bypass as a treatment option for type 1 diabetes.\n\nWe performed a MEDLINE search for articles published from August 1955 to December 2008 using the words \"surgical treatment of diabetes,\" \"etiology of diabetes\" and \"gastric bypass.\"\n\nWe identified 3215 studies and selected 72 relevant papers for review. Surgical treatment of diabetes is evolving from complex pancreatic and islets transplantation surgery for type 1 diabetes with critical postoperative outcome and follow-up to a metabolic surgery, including gastric bypass. Gastric bypass (no immune suppression or graft rejection) has proven to be highly effective treatment for obese patients and nonobese animals with type 2 diabetes. There are certain shared criteria between types 1 and 2 diabetes, making a selected spectrum of the disease a potential target for metabolic surgery to improve or cure diabetes.", "target": "yes", "year": "2009", "labels": ["BACKGROUND", "METHODS", "RESULTS"]}
{"id": "18496363", "question": "Characterization of the gender dimorphism after injury and hemorrhagic shock: are hormonal differences responsible?", "context": "To characterize the gender dimorphism after injury with specific reference to the reproductive age of the women (young,<48 yrs of age, vs. old,>52 yrs of age) in a cohort of severely injured trauma patients for which significant variation in postinjury care is minimized.\n\nSecondary data analysis of an ongoing prospective multicenter cohort study.\n\nAcademic, level I trauma and intensive care unit centers.\n\nBlunt-injured adults with hemorrhagic shock.\n\nNone.\n\nSeparate Cox proportional hazard regression models were formulated based on all patients to evaluate the effects of gender on mortality, multiple organ failure, and nosocomial infection, after controlling for all important confounders. These models were then used to characterize the effect of gender in young and old age groups. Overall mortality, multiple organ failure, and nosocomial infection rates for the entire cohort (n = 1,036) were 20%, 40%, and 45%, respectively. Mean Injury Severity Score was 32 +/- 14 (mean +/- SD). Men (n = 680) and women (n = 356) were clinically similar except that men required higher crystalloid volumes, more often had a history of alcoholism and liver disease, and had greater ventilatory and intensive care unit requirements. Female gender was independently associated with a 43% and 23% lower risk of multiple organ failure and nosocomial infection, respectively. Gender remained an independent risk factor in young and old subgroup analysis, with the protection afforded by female gender remaining unchanged.", "target": "no", "year": "2008", "labels": ["OBJECTIVE", "DESIGN", "SETTING", "PATIENTS", "INTERVENTIONS", "MEASUREMENTS AND MAIN RESULTS"]}
{"id": "16155169", "question": "Percutaneous ethanol injection for benign cystic thyroid nodules: is aspiration of ethanol-mixed fluid advantageous?", "context": "We evaluated the differences between percutaneous ethanol injection with and without aspiration of ethanol-mixed fluid for treatment of benign cystic thyroid nodules.\n\nWe examined 60 patients with benign cystic thyroid nodules confirmed by fine-needle aspiration biopsy and divided them into 2 groups according to nonaspiration (group A, n = 30) or aspiration (group B, n = 30) of ethanol-mixed fluid after intracystic ethanol injection. We evaluated in both groups the complete disappearance of the cystic portion of the thyroid nodule on follow-up ultrasonography (first follow-up ultrasonography; mean, 4.6 months in group A; mean, 4.4 months in group B) (chi-square test), side effects or complications during and after the procedure (chi-square test), and the total procedure time (Student t test).\n\nMost patients showed complete disappearance of the cystic portion of the thyroid nodule (group A, n = 29; group B, n = 28), and they revealed no recurrence on follow-up ultrasonography. There was no statistical difference in the success rates between group A and group B (P>.05). Pain, the most common side effect, and other mild side effects or complications occurred in small numbers of patients in each group, but there was no significant difference in side effects or complications between the 2 groups (P>.05), except for intracystic hemorrhage (P<.05) and the complaint of all group B patients due to a double puncture (P<.001). The total procedure time was nearly double in group B than in group A because of the additional procedures, such as complete evacuation of the ethanol-mixed fluid and the 10-minute compression.", "target": "no", "year": "2005", "labels": ["BACKGROUND AND PURPOSE", "METHODS", "RESULTS"]}
